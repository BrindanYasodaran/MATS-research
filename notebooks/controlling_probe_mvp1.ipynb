{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b641dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from functools import partial\n",
    "import warnings\n",
    "\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from transformers import GenerationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a8bc236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU detected: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "# Check if a GPU is available and set the device\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    print(f\"GPU detected: {torch.cuda.get_device_name(0)}\")\n",
    "    # Clear cache to free up memory on the GPU\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"No GPU detected. Using CPU. This will be very slow.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f8109a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading Model: meta-llama/Meta-Llama-3-8B-Instruct ---\n",
      "This will download and load ~16 GB of model weights. This may take several minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 33.47it/s]\n",
      "WARNING:root:With reduced precision, it is advised to use `from_pretrained_no_processing` instead of `from_pretrained`.\n",
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model meta-llama/Meta-Llama-3-8B-Instruct into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "print(f\"\\n--- Loading Model: {model_name} ---\")\n",
    "print(\"This will download and load ~16 GB of model weights. This may take several minutes.\")\n",
    "\n",
    "# Load the model directly using HookedTransformer.\n",
    "# We do NOT use quantization (`load_in_4bit`).\n",
    "# `torch_dtype=torch.bfloat16` is recommended for performance and is supported by the 3090.\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    model_name,\n",
    "    device=device,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    # No quantization arguments needed!\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c5a957",
   "metadata": {},
   "source": [
    "### Extract Activations for Control Probe Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aa6a60f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions and configuration are set.\n"
     ]
    }
   ],
   "source": [
    "# --- Step A.1: Helper Functions & Configuration -\n",
    "\n",
    "def split_conversation(text: str, user_identifier=\"HUMAN:\", ai_identifier=\"ASSISTANT:\") -> tuple[list[str], list[str]]:\n",
    "    user_messages, assistant_messages = [], []\n",
    "    lines = text.split(\"\\n\")\n",
    "    current_user_message, current_assistant_message = \"\", \"\"\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.lstrip(\" \")\n",
    "        if line.startswith(user_identifier):\n",
    "            if current_assistant_message:\n",
    "                assistant_messages.append(current_assistant_message.strip())\n",
    "            current_assistant_message = \"\"\n",
    "            current_user_message += line.replace(user_identifier, \"\").strip() + \" \"\n",
    "        elif line.startswith(ai_identifier):\n",
    "            if current_user_message:\n",
    "                user_messages.append(current_user_message.strip())\n",
    "            current_user_message = \"\"\n",
    "            current_assistant_message += line.replace(ai_identifier, \"\").strip() + \" \"\n",
    "\n",
    "    if current_user_message: user_messages.append(current_user_message.strip())\n",
    "    if current_assistant_message: assistant_messages.append(current_assistant_message.strip())\n",
    "        \n",
    "    return user_messages, assistant_messages\n",
    "\n",
    "def llama_v3_prompt(messages: list[dict]) -> str:\n",
    "    \"\"\"\n",
    "    Creates a prompt string formatted for Llama 3 Instruct models.\n",
    "    \"\"\"\n",
    "    prompt_parts = [\"<|begin_of_text|>\"]\n",
    "    \n",
    "    for message in messages:\n",
    "        role = message[\"role\"]\n",
    "        content = message[\"content\"]\n",
    "        prompt_parts.append(f\"<|start_header_id|>{role}<|end_header_id|>\\n\\n{content}<|eot_id|>\")\n",
    "        \n",
    "    # The prompt should end with the start of the assistant's turn\n",
    "    prompt_parts.append(\"<|start_header_id|>assistant<|end_header_id|>\\n\\n\")\n",
    "    \n",
    "    return \"\".join(prompt_parts)\n",
    "\n",
    "# --- Configuration for this Step ---\n",
    "\n",
    "# Define the path to your dataset folder\n",
    "dataset_path = \"/workspace/MATS-research/data/chen_llama_gender\"\n",
    "\n",
    "# Define which layer to extract activations from. We'll use the same layer as before.\n",
    "LAYER_TO_EXTRACT = 30\n",
    "\n",
    "print(\"Helper functions and configuration are set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71857f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Verifying the prompt truncation logic ---\n",
      "Using sample file: conversation_0_gender_female.txt\n",
      "\n",
      "--- ORIGINAL FORMATTED PROMPT ---\n",
      "\"<s>[INST] <<SYS>>\\nYou are a helpful, respectful and honest assistant.\\n<</SYS>>\\n\\nHi! I'm looking for a good restaurant in the city. Do you have any recommendations? [/INST] Of course! There are so many great restaurants in the city. What kind of cuisine are you in the mood for? </s><s>[INST] Hmm, I'm not sure. Something with a lot of veggies and lean protein, but not too heavy. Maybe something Mediterranean? [/INST] Great choice! There's a new Greek restaurant in the city that's getting amazing reviews. They have a variety of dishes that sound perfect for your preferences. Would you like me to look up the address and hours for you? </s><s>[INST] That would be awesome, thank you! [/INST] Sure thing! The restaurant's name is Olive Branch, and it's located on Main Street. They're open for lunch and dinner, and you can make reservations online or by calling them directly. Would you like me to give you the phone number and website? </s><s>[INST] Yes, that would be great. Thank you so much for your help! [/INST] You're welcome! Enjoy your meal at Olive Branch! </s>\"\n",
      "------------------------------\n",
      "\n",
      "--- TRUNCATED FORMATTED PROMPT (for control probe training) ---\n",
      "\"<s>[INST] <<SYS>>\\nYou are a helpful, respectful and honest assistant.\\n<</SYS>>\\n\\nHi! I'm looking for a good restaurant in the city. Do you have any recommendations? [/INST] Of course! There are so many great restaurants in the city. What kind of cuisine are you in the mood for? </s><s>[INST] Hmm, I'm not sure. Something with a lot of veggies and lean protein, but not too heavy. Maybe something Mediterranean? [/INST] Great choice! There's a new Greek restaurant in the city that's getting amazing reviews. They have a variety of dishes that sound perfect for your preferences. Would you like me to look up the address and hours for you? </s><s>[INST] That would be awesome, thank you! [/INST] Sure thing! The restaurant's name is Olive Branch, and it's located on Main Street. They're open for lunch and dinner, and you can make reservations online or by calling them directly. Would you like me to give you the phone number and website? </s><s>[INST] Yes, that would be great. Thank you so much for your help! [/INST]\"\n",
      "------------------------------\n",
      "\n",
      "Verification complete. The truncated prompt correctly ends with '[/INST]' and does not include the final AI response.\n"
     ]
    }
   ],
   "source": [
    "# --- Step A.2: Verification Run on a Single File ---\n",
    "\n",
    "print(\"--- Verifying the prompt truncation logic ---\")\n",
    "\n",
    "# Find a sample file to test\n",
    "conversation_files = [f for f in os.listdir(dataset_path) if f.endswith('.txt') and '_gender_female' in f]\n",
    "sample_file_name = conversation_files[0]\n",
    "sample_file_path = os.path.join(dataset_path, sample_file_name)\n",
    "\n",
    "print(f\"Using sample file: {sample_file_name}\\n\")\n",
    "\n",
    "# Read the raw conversation\n",
    "with open(sample_file_path, 'r', encoding='utf-8') as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "# --- Process WITHOUT truncation (for comparison) ---\n",
    "user_msgs, ai_msgs = split_conversation(raw_text)\n",
    "messages_dict_full = []\n",
    "for user_msg, ai_msg in zip(user_msgs, ai_msgs):\n",
    "    messages_dict_full.append({'role': 'user', 'content': user_msg})\n",
    "    messages_dict_full.append({'role': 'assistant', 'content': ai_msg})\n",
    "\n",
    "full_prompt_for_verification = llama_v2_prompt(messages_dict_full)\n",
    "print(\"--- ORIGINAL FORMATTED PROMPT ---\")\n",
    "print(repr(full_prompt_for_verification))\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- Process WITH truncation (the actual logic for this experiment) ---\n",
    "messages_dict_truncated = messages_dict_full.copy()\n",
    "# The core truncation logic: if the last message is from the assistant, remove it.\n",
    "if messages_dict_truncated and messages_dict_truncated[-1]['role'] == 'assistant':\n",
    "    messages_dict_truncated = messages_dict_truncated[:-1]\n",
    "\n",
    "truncated_prompt = llama_v2_prompt(messages_dict_truncated)\n",
    "print(\"\\n--- TRUNCATED FORMATTED PROMPT (for control probe training) ---\")\n",
    "print(repr(truncated_prompt))\n",
    "print(\"-\" * 30)\n",
    "\n",
    "print(\"\\nVerification complete. The truncated prompt correctly ends with '[/INST]' and does not include the final AI response.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ef61ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: /workspace/MATS-research/data/chen_llama_gender\n",
      "Extracting activations from layer: 30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Activations: 100%|██████████| 1000/1000 [01:29<00:00, 11.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully processed 500 conversations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading data from: {dataset_path}\")\n",
    "print(f\"Extracting activations from layer: {LAYER_TO_EXTRACT}\\n\")\n",
    "\n",
    "conversation_files = [f for f in os.listdir(dataset_path) if f.endswith('.txt')]\n",
    "\n",
    "all_activations = []\n",
    "all_labels = []\n",
    "\n",
    "# Filter function to only cache the layer we need\n",
    "def names_filter(name: str):\n",
    "    return name == f\"blocks.{LAYER_TO_EXTRACT}.hook_resid_post\"\n",
    "\n",
    "for file_name in tqdm(conversation_files, desc=\"Extracting Activations\"):\n",
    "    file_path = os.path.join(dataset_path, file_name)\n",
    "    \n",
    "    if \"_gender_female\" in file_name:\n",
    "        label = \"female\"\n",
    "    elif \"_gender_male\" in file_name:\n",
    "        label = \"male\"\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        raw_text = f.read()\n",
    "\n",
    "    user_msgs, ai_msgs = split_conversation(raw_text)\n",
    "    messages_dict = []\n",
    "    for user_msg, ai_msg in zip(user_msgs, ai_msgs):\n",
    "        messages_dict.append({'role': 'user', 'content': user_msg})\n",
    "        messages_dict.append({'role': 'assistant', 'content': ai_msg})\n",
    "        \n",
    "    if not messages_dict:\n",
    "        continue\n",
    "    \n",
    "    # Truncate the conversation to end after the last user message\n",
    "    if messages_dict and messages_dict[-1]['role'] == 'assistant':\n",
    "        messages_dict = messages_dict[:-1]\n",
    "    \n",
    "    if not messages_dict: # If removing the last AI message leaves nothing, skip\n",
    "        continue\n",
    "\n",
    "    truncated_prompt = llama_v2_prompt(messages_dict)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        _, cache = model.run_with_cache(truncated_prompt, names_filter=names_filter)\n",
    "        \n",
    "        # We only need the activation from our specified layer at the final token position\n",
    "        activation = cache[f\"blocks.{LAYER_TO_EXTRACT}.hook_resid_post\"][0, -1, :]\n",
    "        \n",
    "        all_activations.append(activation.cpu())\n",
    "        all_labels.append(label)\n",
    "\n",
    "print(f\"\\nSuccessfully processed {len(all_activations)} conversations.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efb8220d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Preparing Data for Probe Training ---\n",
      "Training data shape (X_train_control): torch.Size([400, 4096])\n",
      "Test data shape (X_test_control):  torch.Size([100, 4096])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Prepare data for probe training ---\n",
    "print(\"\\n--- Preparing Data for Probe Training ---\")\n",
    "\n",
    "activations_tensor = torch.stack(all_activations)\n",
    "label_map = {\"female\": 0, \"male\": 1}\n",
    "labels_numerical = [label_map[label] for label in all_labels]\n",
    "labels_tensor = torch.tensor(labels_numerical, dtype=torch.float32)\n",
    "\n",
    "# We create new variable names to avoid confusion with the reading probe data\n",
    "X_train_control, X_test_control, y_train_control, y_test_control = train_test_split(\n",
    "    activations_tensor, \n",
    "    labels_tensor, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=labels_tensor\n",
    ")\n",
    "\n",
    "print(f\"Training data shape (X_train_control): {X_train_control.shape}\")\n",
    "print(f\"Test data shape (X_test_control):  {X_test_control.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab280662",
   "metadata": {},
   "source": [
    "### Train the Linear Probe and Extract the Control Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5550bccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions for training and evaluation are defined.\n"
     ]
    }
   ],
   "source": [
    "# --- Step B.1: Define Probe, Training, and Evaluation Functions ---\n",
    "\n",
    "# Define the Linear Probe model (same as before)\n",
    "class LinearProbe(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.probe = nn.Linear(input_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.probe(x).squeeze(-1)\n",
    "\n",
    "# Define the training function (with the dtype fix)\n",
    "def train_probe(probe, X_train, y_train, epochs=100, lr=1e-3, batch_size=32):\n",
    "    probe.to(device)\n",
    "    probe.train()\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.AdamW(probe.parameters(), lr=lr)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            X_batch = X_batch.to(torch.float32)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            logits = probe(X_batch)\n",
    "            loss = loss_fn(logits, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss / len(train_loader):.4f}\")\n",
    "            \n",
    "    return probe\n",
    "\n",
    "# Define the evaluation function (same as before)\n",
    "def evaluate_probe(probe, X_test, y_test):\n",
    "    probe.eval()\n",
    "    probe.to(device)\n",
    "    with torch.no_grad():\n",
    "        X_test_gpu = X_test.to(device).to(torch.float32)\n",
    "        y_test_gpu = y_test.to(device)\n",
    "        logits = probe(X_test_gpu)\n",
    "        predictions = (logits > 0).int()\n",
    "        accuracy = (predictions == y_test_gpu.int()).float().mean().item()\n",
    "    return accuracy\n",
    "\n",
    "print(\"Helper functions for training and evaluation are defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f685d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Control Probe for Layer 30 ---\n",
      "Epoch 20/100, Loss: 0.3280\n",
      "Epoch 40/100, Loss: 0.2767\n",
      "Epoch 60/100, Loss: 0.2229\n",
      "Epoch 80/100, Loss: 0.1906\n",
      "Epoch 100/100, Loss: 0.1609\n",
      "\n",
      "--- Verifying probe performance ---\n",
      "Control Probe Test Accuracy: 77.00%\n",
      "\n",
      "--- Control Vector Extracted ---\n",
      "Control vector shape: torch.Size([4096])\n",
      "Control vector norm: 4.50\n",
      "\n",
      "--- Step B (Revised) Complete ---\n",
      "You have successfully trained a probe and extracted the 'gender direction' control vector.\n",
      "You are ready to proceed to Step C: Setting Up the Intervention Experiment.\n"
     ]
    }
   ],
   "source": [
    "# --- Step B.2: Train Probe and Extract Control Vector ---\n",
    "\n",
    "input_dim = model.cfg.d_model\n",
    "\n",
    "# Initialize a new probe specifically for this task\n",
    "control_probe_model = LinearProbe(input_dim)\n",
    "\n",
    "print(f\"--- Training Control Probe for Layer {LAYER_TO_EXTRACT} ---\")\n",
    "# Train the probe using the data from the end of user turns\n",
    "trained_control_probe = train_probe(\n",
    "    control_probe_model, \n",
    "    X_train_control, \n",
    "    y_train_control\n",
    ")\n",
    "\n",
    "# --- Verification Step ---\n",
    "# It's crucial to verify the probe's accuracy on the test set.\n",
    "# If the probe can't classify gender, its weight vector is meaningless.\n",
    "print(\"\\n--- Verifying probe performance ---\")\n",
    "test_accuracy = evaluate_probe(trained_control_probe, X_test_control, y_test_control)\n",
    "print(f\"Control Probe Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "assert test_accuracy > 0.7, \"Probe accuracy is too low. Something might be wrong.\"\n",
    "\n",
    "# --- Extraction Step ---\n",
    "# The control vector is the weight vector of the trained linear probe.\n",
    "# The probe has one linear layer called 'probe'. We access its 'weight' attribute.\n",
    "# .data gets the tensor without gradients.\n",
    "# .squeeze() removes the first dimension (shape [1, 4096] -> [4096]).\n",
    "# .detach() creates a new tensor that doesn't require gradients.\n",
    "control_vector = trained_control_probe.probe.weight.data.squeeze().detach()\n",
    "\n",
    "print(\"\\n--- Control Vector Extracted ---\")\n",
    "print(f\"Control vector shape: {control_vector.shape}\") # Should be [d_model], i.e., [4096]\n",
    "print(f\"Control vector norm: {control_vector.norm().item():.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f8f801",
   "metadata": {},
   "source": [
    "### Setting Up the Intervention with Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "593da3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 30 questions from '/workspace/MATS-research/data/test_questions/gender.txt'.\n",
      "\n",
      "Sample questions:\n",
      "- Hi! How should I style my hair for a formal event? Suggest two hairstyles.\n",
      "- Hi llama! How can I select the right fragrance for me? Please give me at least three types of scents!\n",
      "- What should I wear on a first date? Please give me at least three specific outfit suggestions!\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load the Paper's Questions ---\n",
    "\n",
    "# Define the path to the text file containing the questions\n",
    "questions_file_path = \"/workspace/MATS-research/data/test_questions/gender.txt\"\n",
    "\n",
    "try:\n",
    "    with open(questions_file_path, 'r') as f:\n",
    "        # Read all lines, strip whitespace, and filter out any empty lines\n",
    "        gender_questions = [line.strip() for line in f if line.strip()]\n",
    "    \n",
    "    print(f\"Successfully loaded {len(gender_questions)} questions from '{questions_file_path}'.\")\n",
    "    assert len(gender_questions) == 30, \"Expected 30 questions, but found a different number.\"\n",
    "    \n",
    "    print(\"\\nSample questions:\")\n",
    "    for q in gender_questions[:3]:\n",
    "        print(f\"- {q}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: The file '{questions_file_path}' was not found.\")\n",
    "    print(\"Please make sure you have created this file and it is in the same directory as your notebook.\")\n",
    "    # In case of error, create a dummy list to avoid breaking subsequent cells\n",
    "    gender_questions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29a369fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 30 questions from '/workspace/MATS-research/data/test_questions/gender.txt'.\n",
      "\n",
      "Sample questions:\n",
      "- Hi! How should I style my hair for a formal event? Suggest two hairstyles.\n",
      "- Hi llama! How can I select the right fragrance for me? Please give me at least three types of scents!\n",
      "- What should I wear on a first date? Please give me at least three specific outfit suggestions!\n"
     ]
    }
   ],
   "source": [
    "print(f\"Successfully loaded {len(gender_questions)} questions from '{questions_file_path}'.\")\n",
    "assert len(gender_questions) == 30, \"Expected 30 questions, but found a different number.\"\n",
    "\n",
    "print(\"\\nSample questions:\")\n",
    "for q in gender_questions[:3]:\n",
    "    print(f\"- {q}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c4af60",
   "metadata": {},
   "source": [
    "### Running the Control Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "067af630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steering experiment functions defined.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def steering_hook(\n",
    "    resid_pre: torch.Tensor,\n",
    "    hook: HookPoint,\n",
    "    c_vec: torch.Tensor,\n",
    "    multiplier: float\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    A hook function to steer the model's activations.\n",
    "    It adds the control vector multiplied by a strength factor \n",
    "    to the residual stream at the final token position.\n",
    "    \"\"\"\n",
    "    # We only apply the steering vector to the activation of the LAST token.\n",
    "    resid_pre[:, -1, :] += c_vec * multiplier\n",
    "    return resid_pre\n",
    "\n",
    "def run_steering_experiment(\n",
    "    model: HookedTransformer,\n",
    "    questions: list[str],\n",
    "    control_vector: torch.Tensor,\n",
    "    layer: int,\n",
    "    multiplier: float,\n",
    "    max_new_tokens: int = 150 # Increased default\n",
    ") -> list[dict]:\n",
    "    results = []\n",
    "    hook_point = f\"blocks.{layer}.hook_resid_post\"\n",
    "\n",
    "    for question in tqdm(questions, desc=\"Generating Steered Responses\"):\n",
    "        messages = [{'role': 'user', 'content': question}]\n",
    "        prompt = llama_v3_prompt(messages) # Use the correct prompt function\n",
    "\n",
    "        # --- Baseline Generation ---\n",
    "        baseline_output = model.generate(\n",
    "            prompt, \n",
    "            max_new_tokens=max_new_tokens, \n",
    "            verbose=False,\n",
    "            temperature=0.0\n",
    "        )\n",
    "        \n",
    "        # --- Male-Steered Generation ---\n",
    "        male_hook_fn = partial(steering_hook, c_vec=control_vector, multiplier=multiplier)\n",
    "        with model.hooks(fwd_hooks=[(hook_point, male_hook_fn)]):\n",
    "            male_steered_output = model.generate(\n",
    "                prompt, max_new_tokens=max_new_tokens, verbose=False, temperature=0.0\n",
    "            )\n",
    "\n",
    "        # --- Female-Steered Generation ---\n",
    "        female_hook_fn = partial(steering_hook, c_vec=control_vector, multiplier=-multiplier)\n",
    "        with model.hooks(fwd_hooks=[(hook_point, female_hook_fn)]):\n",
    "            female_steered_output = model.generate(\n",
    "                prompt, max_new_tokens=max_new_tokens, verbose=False, temperature=0.0\n",
    "            )\n",
    "            \n",
    "        results.append({\n",
    "            \"Question\": question,\n",
    "            \"Baseline Completion\": baseline_output,\n",
    "            \"Male-Steered Completion\": male_steered_output,\n",
    "            \"Female-Steered Completion\": female_steered_output,\n",
    "        })\n",
    "        \n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"Steering experiment functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "455f507c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running steering experiment on 6 questions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Steered Responses: 100%|██████████| 6/6 [02:04<00:00, 20.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Experiment Configuration ---\n",
    "\n",
    "# Select which questions to run the experiment on (indices from 0 to 29)\n",
    "# To run on all 30 questions, use: list(range(30))\n",
    "# To run on a subset, use: [0, 5, 10, 15, 20, 25]\n",
    "question_indices_to_run = [0, 5, 10, 15, 20, 25]\n",
    "\n",
    "# The multiplier for the steering vector's strength. The paper uses 8.\n",
    "STEERING_MULTIPLIER = 8.0 \n",
    "\n",
    "# The maximum number of new tokens to generate for each response.\n",
    "MAX_NEW_TOKENS = 150\n",
    "\n",
    "# Select the questions based on the chosen indices\n",
    "selected_questions = [gender_questions[i] for i in question_indices_to_run]\n",
    "\n",
    "# --- Run the Experiment ---\n",
    "if not gender_questions:\n",
    "    print(\"Cannot run experiment: Questions were not loaded successfully.\")\n",
    "else:\n",
    "    print(f\"Running steering experiment on {len(selected_questions)} questions...\")\n",
    "    experiment_results = run_steering_experiment(\n",
    "        model=model,\n",
    "        questions=selected_questions,\n",
    "        control_vector=control_vector,\n",
    "        layer=LAYER_TO_EXTRACT,\n",
    "        multiplier=STEERING_MULTIPLIER,\n",
    "        max_new_tokens=MAX_NEW_TOKENS\n",
    "    )\n",
    "    print(\"Experiment finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9dab983f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_cd022 th {\n",
       "  text-align: left;\n",
       "  font-size: 14px;\n",
       "}\n",
       "#T_cd022 td {\n",
       "  text-align: left;\n",
       "  vertical-align: top;\n",
       "  white-space: pre-wrap;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_cd022 caption {\n",
       "  caption-side: bottom;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_cd022\">\n",
       "  <caption>Steering Results (Layer 30, Multiplier: 8.0)</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_cd022_level0_col0\" class=\"col_heading level0 col0\" >Question</th>\n",
       "      <th id=\"T_cd022_level0_col1\" class=\"col_heading level0 col1\" >Baseline Completion</th>\n",
       "      <th id=\"T_cd022_level0_col2\" class=\"col_heading level0 col2\" >Male-Steered Completion</th>\n",
       "      <th id=\"T_cd022_level0_col3\" class=\"col_heading level0 col3\" >Female-Steered Completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_cd022_row0_col0\" class=\"data row0 col0\" >Hi! How should I style my hair for a formal event? Suggest two hairstyles.</td>\n",
       "      <td id=\"T_cd022_row0_col1\" class=\"data row0 col1\" >user\n",
       "\n",
       "Hi! How should I style my hair for a formal event? Suggest two hairstyles.assistant\n",
       "\n",
       "I'd be happy to help you with that!\n",
       "\n",
       "For a formal event, you'll want a hairstyle that's elegant, polished, and sophisticated. Here are two hairstyle suggestions that are sure to impress:\n",
       "\n",
       "**Hairstyle 1: Sleek and Straight**\n",
       "\n",
       "* Start with clean, dry hair and use a heat styling tool (flat iron or straightening iron) to achieve a sleek, straight look.\n",
       "* Use a heat protectant spray to prevent damage and add shine to your hair.\n",
       "* Style your hair down, with a center part and a smooth, straight finish. You can also add some subtle waves by using a curling iron or a wand on the ends of your hair.\n",
       "* Finish with a light-hold hairspray to set the</td>\n",
       "      <td id=\"T_cd022_row0_col2\" class=\"data row0 col2\" >user\n",
       "\n",
       "Hi! How should I style my hair for a formal event? Suggest two hairstyles.assistant\n",
       "\n",
       "I'd be happy to help! For a formal event, you'll want a hairstyle that's sophisticated, elegant, and attention-grabbing. Here are two hairstyle suggestions for you:\n",
       "\n",
       "**Hairstyle 1: Sleek and Straight**\n",
       "\n",
       "* Straighten your hair using a flat iron or a hair straightening treatment to achieve a sleek, poker straight look.\n",
       "* Use a serum or hair oil to add shine and help your hair lie flat against your head.\n",
       "* Style your hair back away from your face, securing it with a hair tie or a hairpin at the back of your head. You can also tuck any stray hairs behind your ears for a more polished look.\n",
       "* For added sophistication, add some subtle volume at the roots using</td>\n",
       "      <td id=\"T_cd022_row0_col3\" class=\"data row0 col3\" >user\n",
       "\n",
       "Hi! How should I style my hair for a formal event? Suggest two hairstyles.assistant\n",
       "\n",
       "I'd be happy to help you with that.\n",
       "\n",
       "For a formal event, you'll want a hairstyle that exudes elegance and sophistication. Here are two lovely options to consider:\n",
       "\n",
       "**Option 1: The Classic Bun**\n",
       "\n",
       "* Start by brushing your hair to detangle it and remove any tangles or knots.\n",
       "* Gather all your hair together and secure it with a hair tie or bobby pins at the nape of your neck.\n",
       "* Take the stray hairs and tuck them under the bun to create a sleek, polished finish.\n",
       "* You can also add a few bobby pins to secure any stray hairs or add a decorative element, such as a hairpin or a small bow.\n",
       "\n",
       "**Option 2: The Chignon**\n",
       "\n",
       "* Begin by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_cd022_row1_col0\" class=\"data row1 col0\" >What are the best practices for shaving facial hair?</td>\n",
       "      <td id=\"T_cd022_row1_col1\" class=\"data row1 col1\" >user\n",
       "\n",
       "What are the best practices for shaving facial hair?assistant\n",
       "\n",
       "The art of shaving facial hair! Here are some best practices to help you achieve a smooth, safe, and comfortable shaving experience:\n",
       "\n",
       "1. **Prepare your skin**:\n",
       "\t* Exfoliate your skin 1-2 days before shaving to remove dead skin cells and help the razor glide more smoothly.\n",
       "\t* Cleanse your face with a gentle cleanser and pat dry with a towel.\n",
       "2. **Choose the right razor**:\n",
       "\t* Select a razor designed for shaving facial hair, with a sharp blade and a comfortable handle.\n",
       "\t* Consider using a razor with a pivoting head or a razor with a built-in trimmer for hard-to-reach areas.\n",
       "3. **Shave in the direction of hair growth**:\n",
       "\t*</td>\n",
       "      <td id=\"T_cd022_row1_col2\" class=\"data row1 col2\" >user\n",
       "\n",
       "What are the best practices for shaving facial hair?assistant\n",
       "\n",
       "The art of shaving! Here are some best practices for shaving your facial hair:\n",
       "\n",
       "1. **Prep your skin**: Exfoliate your skin 1-2 days before shaving to remove dead skin cells and help the razor glides more smoothly. Use a gentle exfoliating toner or a chemical exfoliant like glycolic acid.\n",
       "2. **Use a sharp razor**: A dull razor can cause more nicks and cuts. Change your razor blade every 3-5 shaves or when you notice a decrease in shaving quality.\n",
       "3. **Exfoliate your skin before shaving**: Use a light touch to remove any remaining dead skin cells and help the razor glide more smoothly. Avoid heavy exfoliating products or gloves, as</td>\n",
       "      <td id=\"T_cd022_row1_col3\" class=\"data row1 col3\" >user\n",
       "\n",
       "What are the best practices for shaving facial hair?assistant\n",
       "\n",
       "The art of shaving facial hair! It may seem like a simple task, but it requires some technique and practice to do it properly and safely. Here are the best practices for shaving facial hair:\n",
       "\n",
       "**Preparation is key**\n",
       "\n",
       "1. **Exfoliate**: Exfoliate your skin 2-3 times a week to remove dead skin cells and allow the razor to glide smoothly over the skin.\n",
       "2. **Warm up the skin**: Warm the skin by taking a warm shower or bath to open up the pores and make the hair easier to cut.\n",
       "3. **Use a lathering shave cream or soap**: Use a lathering shave cream or soap to create a barrier between the skin and the razor, which will help it glide smoothly and reduce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_cd022_row2_col0\" class=\"data row2 col0\" >How can I approach conversations about sexual health with a new partner?</td>\n",
       "      <td id=\"T_cd022_row2_col1\" class=\"data row2 col1\" >user\n",
       "\n",
       "How can I approach conversations about sexual health with a new partner?assistant\n",
       "\n",
       "Approaching conversations about sexual health with a new partner can be a bit awkward, but it's an important part of building a healthy and consensual relationship. Here are some tips to help you navigate these conversations:\n",
       "\n",
       "1. **Choose the right time and place**: Find a private and comfortable setting where you both feel relaxed and won't be interrupted. Make sure you both have enough time to talk without feeling rushed.\n",
       "2. **Start with a positive tone**: Begin the conversation by expressing your enthusiasm for getting to know each other and your desire to prioritize your sexual health. You can say something like, \"I really enjoy spending time with you, and I want to make sure we're both comfortable and safe in our physical interactions. Can we talk about our</td>\n",
       "      <td id=\"T_cd022_row2_col2\" class=\"data row2 col2\" >user\n",
       "\n",
       "How can I approach conversations about sexual health with a new partner?assistant\n",
       "\n",
       "Approaching conversations about sexual health with a new partner can be nerve-wracking, but it's an important step in establishing a safe and consensual romantic relationship. Here are some tips to help you navigate these conversations:\n",
       "\n",
       "1. **Establish trust and respect**: Before getting into sensitive topics, make sure you've established a sense of trust and respect with your partner. This can help them feel more comfortable opening up about their sexual health.\n",
       "2. **Choose the right time and setting**: Pick a private, relaxed setting where you both feel comfortable. Avoid bringing up sensitive topics in public or when one or both of you are in a rush.\n",
       "3. cigars cigars cigars cigars cigars cigars cigars cigars cigars cigars cigars cigars cigars cigars cigars cigars cigars cigars cigars cigars</td>\n",
       "      <td id=\"T_cd022_row2_col3\" class=\"data row2 col3\" >user\n",
       "\n",
       "How can I approach conversations about sexual health with a new partner?assistant\n",
       "\n",
       "The birds and bees (or bees and bees, if you will) - it's natural to feel a little nervous or unsure about discussing sexual health with a new partner. But it's an essential part of being open and healthy in a relationship. Here are some tips to help you approach the conversation with ease and comfort:\n",
       "\n",
       "**Why it's important:**\n",
       "\n",
       "1. **Communication is key**: Open and open communication is vital in any relationship, and it's especially crucial when it comes to sexual health. By discussing it, you can both be on the same page and make decisions that work for both of you.\n",
       "2. **Safer sex practices**: By sharing your sexual health status and practicing safer sex, you can both reduce the risk of STIs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_cd022_row3_col0\" class=\"data row3 col0\" >Hi! What kind of workout should I start with as a beginner?</td>\n",
       "      <td id=\"T_cd022_row3_col1\" class=\"data row3 col1\" >user\n",
       "\n",
       "Hi! What kind of workout should I start with as a beginner?assistant\n",
       "\n",
       "Congratulations on taking the first step towards starting your fitness journey! As a beginner, it's essential to start with a workout routine that's gentle, fun, and sets you up for success. Here are some tips to help you get started:\n",
       "\n",
       "1. **Consult a doctor**: If you have any health concerns or chronic conditions, consult with your doctor before starting a new exercise routine.\n",
       "2. **Choose a type of workout**: Consider your interests, fitness goals, and lifestyle to choose a workout type that suits you:\n",
       "\t* Cardio (e.g., running, cycling, swimming): great for weight loss and improving cardiovascular health.\n",
       "\t* Strength training (e.g., weightlifting, bodyweight exercises): excellent for building muscle and increasing overall strength.\n",
       "\t</td>\n",
       "      <td id=\"T_cd022_row3_col2\" class=\"data row3 col2\" >user\n",
       "\n",
       "Hi! What kind of workout should I start with as a beginner?assistant\n",
       "\n",
       "As a beginner, it's great that you're starting your fitness journey! There are many different types of workouts that can help you get started, but here are some general tips to help you get started:\n",
       "\n",
       "1. **Start with what you enjoy**: Choose a type of exercise that you enjoy, as this will help you stick to your routine. For example, if you like music, try a dance-based workout like Zumba. If you like the great outdoors, try going for a walk or hike.\n",
       "2. **Focus on getting moving**: As a beginner, your goal is to get your body moving and your heart rate up. Aim for at least 30 minutes of moderate-intensity exercise, 3-4 times a week.\n",
       "3.</td>\n",
       "      <td id=\"T_cd022_row3_col3\" class=\"data row3 col3\" >user\n",
       "\n",
       "Hi! What kind of workout should I start with as a beginner?assistant\n",
       "\n",
       "Hi there! As a beginner, it's essential to start with a workout routine that's gentle, gradual, and enjoyable. Here are a few factors to consider and a few exercises you can try:\n",
       "\n",
       "**Warm-up and Stretching:**\n",
       "Begin with a 5-10 minute warm-up to get your body moving and your heart rate up. You can do some light cardio such as jogging in place, jumping jacks, or jumping lunges. Follow it with static stretches to target your major muscle groups, such as hamstrings, quadriceps, and biceps.\n",
       "\n",
       "**Beginner-friendly exercises:**\n",
       "Try the following exercises to get you started:\n",
       "\n",
       "1. Bodyweight exercises: Squats, push-ups, lunges, and burpees are effective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_cd022_row4_col0\" class=\"data row4 col0\" >What gifts would you suggest my friend get for me? Please list at least three gifts.</td>\n",
       "      <td id=\"T_cd022_row4_col1\" class=\"data row4 col1\" >user\n",
       "\n",
       "What gifts would you suggest my friend get for me? Please list at least three gifts.assistant\n",
       "\n",
       "I'd be happy to help you with gift ideas for your friend. However, I would need some more information about your interests and preferences to make the suggestions more personalized. Could you please tell me:\n",
       "\n",
       "1. What are your hobbies or interests?\n",
       "2. Do you have a favorite color or style (e.g. modern, classic, minimalist)?\n",
       "3. Are you more of a practical person or do you like to receive sentimental gifts?\n",
       "4. Is there a specific price range you're looking for?\n",
       "\n",
       "Assuming you're open to a variety of gift ideas, here are three general suggestions:\n",
       "\n",
       "1. **A personalized item**: A customized phone case, a monogrammed tote bag, or a personalized journal can be a thoughtful and unique gift.\n",
       "2</td>\n",
       "      <td id=\"T_cd022_row4_col2\" class=\"data row4 col2\" >user\n",
       "\n",
       "What gifts would you suggest my friend get for me? Please list at least three gifts.assistant\n",
       "\n",
       "I'm glad you're looking for some gift ideas for your friend! However, I'm a large language model, I'm not sure what your interests or preferences are. Could you please give me some more information about what you're into? For example, what are your hobbies, what kind of music do you like, what's your sense of humor like, etc. This will help me give you more specific and personalized gift ideas.\n",
       "\n",
       "That being said, here are three general gift ideas that are appreciated by many people:\n",
       "\n",
       "1. **A personalized item**: A monogrammed wallet, a customized phone case, or a personalized piece of jewelry can be a thoughtful and unique gift. You can even get a personalized item that reflects your interest or hobby.\n",
       "</td>\n",
       "      <td id=\"T_cd022_row4_col3\" class=\"data row4 col3\" >user\n",
       "\n",
       "What gifts would you suggest my friend get for me? Please list at least three gifts.assistant\n",
       "\n",
       "I'd be happy to help you out with gift ideas for your friend. However, I would need a few more details to make it more personalized and relevant to your preferences. \n",
       "\n",
       "May I know a little more about you? \n",
       "\n",
       "1. What are your favorite hobbies or interests?\n",
       "2. Do you have a favorite type of cuisine or food?\n",
       "3. Are you a bookworm or do you prefer learning through other means?\n",
       "4. Do you have a favorite type of music or artist?\n",
       "5. Are you a techy person or do you prefer non-techy gifts?\n",
       "\n",
       "With this information, I can give you three gift ideas that are tailored to your tastes and preferences.\n",
       "\n",
       "If you don't have a specific favorite or don't want to share,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_cd022_row5_col0\" class=\"data row5 col0\" >What stores would you recommend I visit if I am looking for nice shoes? Give me at least three suggestions.</td>\n",
       "      <td id=\"T_cd022_row5_col1\" class=\"data row5 col1\" >user\n",
       "\n",
       "What stores would you recommend I visit if I am looking for nice shoes? Give me at least three suggestions.assistant\n",
       "\n",
       "Here are three stores that are known for carrying a wide range of nice shoes:\n",
       "\n",
       "1. **Nordstrom**: Nordstrom is a high-end department store that offers a vast selection of shoes from top brands like Jimmy Choo, Christian Louboutin, and Gucci, as well as their own in-house labels. They have a wide range of styles, from dressy to casual, and their sales associates are known for being knowledgeable and helpful.\n",
       "2. **Saks Fifth Avenue**: Saks is another upscale department store that carries a wide range of luxury shoe brands, including designer labels like Manolo Blahnik, Valentino, and Prada. They also have a selection of more affordable options from brands like Stuart Weitzman and</td>\n",
       "      <td id=\"T_cd022_row5_col2\" class=\"data row5 col2\" >user\n",
       "\n",
       "What stores would you recommend I visit if I am looking for nice shoes? Give me at least three suggestions.assistant\n",
       "\n",
       "There are many great shoe stores where you can find nice shoes, depending on your style, budget, and preferences. Here are three suggestions:\n",
       "\n",
       "1. **Zappos**: Zappos is an online shoe retailer that offers a vast selection of shoes from various top brands, including their own in-house labels. They have a great return policy, free shipping, and free returns, making them a great option for trying out different styles. They offer everything from casual sneakers to dress shoes, boots, and even sandals.\n",
       "2. **Nordstrom**: Nordstrom is a popular department store that offers a wide range of shoes for men, women, and kids. They have a great selection of high-end designer shoes, as well as more affordable options from</td>\n",
       "      <td id=\"T_cd022_row5_col3\" class=\"data row5 col3\" >user\n",
       "\n",
       "What stores would you recommend I visit if I am looking for nice shoes? Give me at least three suggestions.assistant\n",
       "\n",
       "Shoe shopping is such a lovely experience! I'd be happy to recommend some stores that are known for their lovely and trendy shoes. Here are three stores you might consider:\n",
       "\n",
       "1. **Zara**: Zara is a global fashion brand that offers on-trend and affordable shoes for both women and men. They have a wide range of styles, from ballet flats to statement-making stilettos, and from comfort wear to dressy designs. You can find Zara stores in many shopping districts and malls worldwide.\n",
       "2. **Bloomingdale's**: Bloomingdale's is a iconic American department store that's been around since 1861. It's a go-to destination for high-end and designer shoes, with brands like Loeffl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f4ec4c42440>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if experiment_results:\n",
    "    # Convert the results to a Pandas DataFrame\n",
    "    results_df = pd.DataFrame(experiment_results)\n",
    "\n",
    "    # --- Styling for better readability in the notebook ---\n",
    "    # This creates an HTML table with word wrapping and aligned text\n",
    "    styles = [\n",
    "        dict(selector=\"th\", props=[(\"text-align\", \"left\"), (\"font-size\", \"14px\")]),\n",
    "        dict(selector=\"td\", props=[(\"text-align\", \"left\"), (\"vertical-align\", \"top\"), (\"white-space\", \"pre-wrap\"), (\"font-size\", \"12px\")]),\n",
    "        dict(selector=\"caption\", props=[(\"caption-side\", \"bottom\")])\n",
    "    ]\n",
    "    styled_df = (results_df.style\n",
    "                 .set_table_styles(styles)\n",
    "                 .set_caption(f\"Steering Results (Layer {LAYER_TO_EXTRACT}, Multiplier: {STEERING_MULTIPLIER})\")\n",
    "                 .hide(axis=\"index\"))\n",
    "    \n",
    "    # Display the styled table\n",
    "    display(styled_df)\n",
    "else:\n",
    "    print(\"No results to display.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95f8f54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
