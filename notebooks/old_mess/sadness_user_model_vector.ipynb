{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "30f71dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from functools import partial\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3becec",
   "metadata": {},
   "source": [
    "# Obtaining user model vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61bba935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 79.85it/s]\n",
      "WARNING:root:With reduced precision, it is advised to use `from_pretrained_no_processing` instead of `from_pretrained`.\n",
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model meta-llama/Meta-Llama-3-8B-Instruct into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set the device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    device=device,\n",
    "    torch_dtype=torch.bfloat16 # Use bfloat16 to save memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f8d0cc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total happy prompts: 505\n",
      "Total sad prompts: 532\n"
     ]
    }
   ],
   "source": [
    "def load_data(filepath):\n",
    "    with open(filepath, encoding='utf-8') as f:\n",
    "        return [l.strip() for l in f if l.strip()]\n",
    "\n",
    "\n",
    "happy_filepath = '/workspace/MATS-research/data/emotion_user_prompts/happiness.txt'\n",
    "sad_filepath = '/workspace/MATS-research/data/emotion_user_prompts/sadness.txt' # Assuming you have a sadness.txt file\n",
    "\n",
    "all_happy_prompts = load_data(happy_filepath)\n",
    "all_sad_prompts   = load_data(sad_filepath)\n",
    "\n",
    "\n",
    "print(f\"Total happy prompts: {len(all_happy_prompts)}\")\n",
    "print(f\"Total sad prompts: {len(all_sad_prompts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "131467af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting activations from all sad prompts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 17/17 [00:03<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting activations from all happy prompts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 16/16 [00:02<00:00,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished. Example shape for layer 15 (sad): torch.Size([532, 4096])\n",
      "Finished. Example shape for layer 15 (happy): torch.Size([505, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_last_token_activations(model, tokenizer, prompts, layers, batch_size=32):\n",
    "    \"\"\"\n",
    "    Extracts residual stream activations at the last token position for specified layers.\n",
    "    \"\"\"\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        \n",
    "    activations = defaultdict(list)\n",
    "    \n",
    "    for i in tqdm(range(0, len(prompts), batch_size), desc=\"Processing Batches\"):\n",
    "        batch_prompts = prompts[i:i+batch_size]\n",
    "        \n",
    "        tokenizer.padding_side = \"left\"\n",
    "        tokens = tokenizer(batch_prompts, return_tensors=\"pt\", padding=True)\n",
    "        \n",
    "        seq_lengths = (tokens.input_ids != tokenizer.pad_token_id).sum(dim=1) - 1\n",
    "        \n",
    "        hook_names = [f\"blocks.{layer}.hook_resid_post\" for layer in layers]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            _, cache = model.run_with_cache(\n",
    "                tokens.input_ids.to(model.cfg.device), \n",
    "                names_filter=lambda name: name in hook_names\n",
    "            )\n",
    "\n",
    "        for layer in layers:\n",
    "            hook_name = f\"blocks.{layer}.hook_resid_post\"\n",
    "            layer_activations = cache[hook_name].cpu()\n",
    "            \n",
    "            for j, length in enumerate(seq_lengths):\n",
    "                last_token_activation = layer_activations[j, length, :]\n",
    "                activations[layer].append(last_token_activation)\n",
    "\n",
    "    for layer in activations:\n",
    "        activations[layer] = torch.stack(activations[layer])\n",
    "        \n",
    "    return activations\n",
    "\n",
    "# Specify the target layers you want to create probes for\n",
    "target_layers = list(range(15, 31))\n",
    "\n",
    "print(\"\\nExtracting activations from all sad prompts...\")\n",
    "sad_activations = get_last_token_activations(model, model.tokenizer, all_sad_prompts, target_layers)\n",
    "\n",
    "print(\"\\nExtracting activations from all happy prompts...\")\n",
    "happy_activations = get_last_token_activations(model, model.tokenizer, all_happy_prompts, target_layers)\n",
    "\n",
    "print(f\"\\nFinished. Example shape for layer 15 (sad): {sad_activations[15].shape}\")\n",
    "print(f\"Finished. Example shape for layer 15 (happy): {happy_activations[15].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d25f6f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Splitting activations into training and validation sets for probe training...\n",
      "\n",
      "--- Data for Layer 18 ---\n",
      "Shape of X_train: torch.Size([829, 4096])\n",
      "Shape of y_train: torch.Size([829])\n",
      "Shape of X_val: torch.Size([208, 4096])\n",
      "Shape of y_val: torch.Size([208])\n",
      "Training set balance: 425 sad samples, 404 happy samples.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def prepare_data_for_probe_training(sad_activations, happy_activations, layers, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Combines sad and happy activations, creates labels, and splits into train/validation sets.\n",
    "    \"\"\"\n",
    "    train_data = {}\n",
    "    val_data = {}\n",
    "\n",
    "    for layer in layers:\n",
    "        sad_acts = sad_activations[layer]\n",
    "        happy_acts = happy_activations[layer]\n",
    "        \n",
    "        all_activations = torch.cat([sad_acts, happy_acts], dim=0)\n",
    "        \n",
    "        sad_labels = torch.ones(sad_acts.shape[0], dtype=torch.long)\n",
    "        happy_labels = torch.zeros(happy_acts.shape[0], dtype=torch.long)\n",
    "        all_labels = torch.cat([sad_labels, happy_labels], dim=0)\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            all_activations, \n",
    "            all_labels, \n",
    "            test_size=test_size, \n",
    "            random_state=random_state,\n",
    "            stratify=all_labels\n",
    "        )\n",
    "        \n",
    "        train_data[layer] = {'X_train': X_train, 'y_train': y_train}\n",
    "        val_data[layer] = {'X_val': X_val, 'y_val': y_val}\n",
    "\n",
    "    return train_data, val_data\n",
    "\n",
    "print(\"\\nSplitting activations into training and validation sets for probe training...\")\n",
    "probe_train_data, probe_val_data = prepare_data_for_probe_training(\n",
    "    sad_activations, \n",
    "    happy_activations, \n",
    "    target_layers\n",
    ")\n",
    "\n",
    "# --- Verification ---\n",
    "example_layer = 18\n",
    "print(f\"\\n--- Data for Layer {example_layer} ---\")\n",
    "print(f\"Shape of X_train: {probe_train_data[example_layer]['X_train'].shape}\")\n",
    "print(f\"Shape of y_train: {probe_train_data[example_layer]['y_train'].shape}\")\n",
    "print(f\"Shape of X_val: {probe_val_data[example_layer]['X_val'].shape}\")\n",
    "print(f\"Shape of y_val: {probe_val_data[example_layer]['y_val'].shape}\")\n",
    "\n",
    "sad_count = (probe_train_data[example_layer]['y_train'] == 1).sum()\n",
    "happy_count = (probe_train_data[example_layer]['y_train'] == 0).sum()\n",
    "print(f\"Training set balance: {sad_count} sad samples, {happy_count} happy samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c2fa575c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LinearProbe(nn.Module):\n",
    "    \"\"\"A simple linear probe for classification.\"\"\"\n",
    "    def __init__(self, d_model):\n",
    "        super().__init__()\n",
    "        # For a binary task (happy vs. sad), we only need one output logit.\n",
    "        # A positive logit will predict \"sad\" (class 1), negative will predict \"happy\" (class 0).\n",
    "        self.probe = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # We return the raw logit, the loss function will handle the sigmoid\n",
    "        return self.probe(x).squeeze(-1)\n",
    "\n",
    "# --- Phase 5: Training and Evaluation Loop ---\n",
    "def train_probe(probe, train_loader, val_loader, optimizer, criterion, n_epochs=10, device=\"cuda\"):\n",
    "    \"\"\"A standard training loop for the probe.\"\"\"\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        probe.train()\n",
    "        epoch_train_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            # THE FIX IS HERE: Ensure input tensor has the same dtype as the probe's weights\n",
    "            X_batch, y_batch = X_batch.to(device).to(torch.float32), y_batch.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            logits = probe(X_batch)\n",
    "            loss = criterion(logits, y_batch.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_train_loss += loss.item()\n",
    "        \n",
    "        train_losses.append(epoch_train_loss / len(train_loader))\n",
    "        \n",
    "        # Validation\n",
    "        probe.eval()\n",
    "        epoch_val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                # AND THE FIX IS HERE for the validation loop\n",
    "                X_batch, y_batch = X_batch.to(device).to(torch.float32), y_batch.to(device)\n",
    "                \n",
    "                logits = probe(X_batch)\n",
    "                loss = criterion(logits, y_batch.float())\n",
    "                epoch_val_loss += loss.item()\n",
    "                \n",
    "                # Accuracy calculation\n",
    "                preds = (torch.sigmoid(logits) > 0.5).long()\n",
    "                correct += (preds == y_batch).sum().item()\n",
    "                total += y_batch.size(0)\n",
    "        \n",
    "        val_losses.append(epoch_val_loss / len(val_loader))\n",
    "        val_accuracies.append(correct / total)\n",
    "    \n",
    "    return {\n",
    "        \"final_val_accuracy\": val_accuracies[-1],\n",
    "        \"val_accuracies\": val_accuracies,\n",
    "        \"train_losses\": train_losses,\n",
    "        \"val_losses\": val_losses\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ac9e3c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dictionary to store trained probes and their results\n",
    "trained_probes = {}\n",
    "probe_results = {}\n",
    "\n",
    "# Training Hyperparameters\n",
    "LEARNING_RATE = 1e-3\n",
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "# The loss function combines a Sigmoid layer with Binary Cross Entropy.\n",
    "# It's numerically more stable than using a Sigmoid layer in the probe and then BCELoss.\n",
    "criterion = nn.BCEWithLogitsLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "14f4a35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Probes for Each Layer:   6%|▋         | 1/16 [00:00<00:04,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 15: Final Validation Accuracy = 0.7260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Probes for Each Layer:  12%|█▎        | 2/16 [00:00<00:03,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 16: Final Validation Accuracy = 0.7548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Probes for Each Layer:  19%|█▉        | 3/16 [00:00<00:03,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 17: Final Validation Accuracy = 0.7404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Probes for Each Layer:  25%|██▌       | 4/16 [00:00<00:02,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 18: Final Validation Accuracy = 0.7356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Probes for Each Layer:  31%|███▏      | 5/16 [00:01<00:02,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 19: Final Validation Accuracy = 0.7404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Probes for Each Layer:  38%|███▊      | 6/16 [00:01<00:02,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 20: Final Validation Accuracy = 0.7404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Probes for Each Layer:  44%|████▍     | 7/16 [00:01<00:02,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 21: Final Validation Accuracy = 0.7404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Probes for Each Layer:  50%|█████     | 8/16 [00:01<00:01,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 22: Final Validation Accuracy = 0.7644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Probes for Each Layer:  56%|█████▋    | 9/16 [00:02<00:01,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 23: Final Validation Accuracy = 0.7644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Probes for Each Layer:  62%|██████▎   | 10/16 [00:02<00:01,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 24: Final Validation Accuracy = 0.7692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Probes for Each Layer:  69%|██████▉   | 11/16 [00:02<00:01,  4.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 25: Final Validation Accuracy = 0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Probes for Each Layer:  75%|███████▌  | 12/16 [00:02<00:00,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 26: Final Validation Accuracy = 0.7596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Probes for Each Layer:  81%|████████▏ | 13/16 [00:02<00:00,  4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 27: Final Validation Accuracy = 0.7644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Probes for Each Layer:  88%|████████▊ | 14/16 [00:03<00:00,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 28: Final Validation Accuracy = 0.7548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Probes for Each Layer:  94%|█████████▍| 15/16 [00:03<00:00,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 29: Final Validation Accuracy = 0.7788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Probes for Each Layer: 100%|██████████| 16/16 [00:03<00:00,  4.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 30: Final Validation Accuracy = 0.7692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop through each layer and train a probe\n",
    "for layer in tqdm(target_layers, desc=\"Training Probes for Each Layer\"):\n",
    "    # Create datasets and dataloaders for the current layer\n",
    "    train_dataset = TensorDataset(probe_train_data[layer]['X_train'], probe_train_data[layer]['y_train'])\n",
    "    val_dataset = TensorDataset(probe_val_data[layer]['X_val'], probe_val_data[layer]['y_val'])\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    # Initialize the probe and optimizer\n",
    "    d_model = model.cfg.d_model\n",
    "    probe = LinearProbe(d_model).to(device)\n",
    "    optimizer = torch.optim.Adam(probe.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    # Train the probe\n",
    "    results = train_probe(probe, train_loader, val_loader, optimizer, criterion, n_epochs=NUM_EPOCHS, device=device)\n",
    "    \n",
    "    # Store the trained probe and its results\n",
    "    trained_probes[layer] = probe\n",
    "    probe_results[layer] = results\n",
    "    \n",
    "    print(f\"Layer {layer}: Final Validation Accuracy = {results['final_val_accuracy']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f5214446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best probe is from Layer 29 with a validation accuracy of 0.7788\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_layer = -1\n",
    "best_accuracy = -1\n",
    "for layer, results in probe_results.items():\n",
    "    if results['final_val_accuracy'] > best_accuracy:\n",
    "        best_accuracy = results['final_val_accuracy']\n",
    "        best_layer = layer\n",
    "\n",
    "print(f\"\\nBest probe is from Layer {best_layer} with a validation accuracy of {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "35624fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted sadness vector from Layer 29 probe.\n",
      "Vector shape: torch.Size([4096])\n",
      "Vector norm: 1.4876\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Use the best layer you found from the previous step\n",
    "best_layer = 29\n",
    "best_probe = trained_probes[best_layer]\n",
    "\n",
    "# The steering vector is the weight of the linear probe.\n",
    "# The probe has one output logit, so its weight matrix has shape [1, d_model].\n",
    "# We just want the vector, so we take the first (and only) row.\n",
    "sadness_vector = best_probe.probe.weight[0].detach()\n",
    "\n",
    "print(f\"Extracted sadness vector from Layer {best_layer} probe.\")\n",
    "print(f\"Vector shape: {sadness_vector.shape}\")\n",
    "print(f\"Vector norm: {torch.linalg.norm(sadness_vector).item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e463ae7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_steering_with_probe_vector(model, tokenizer, prompt, layer, steering_vector, steering_coefficient):\n",
    "    \"\"\"\n",
    "    Tests the effect of the probe's steering vector on a single prompt.\n",
    "    \"\"\"\n",
    "    # --- 1. Generate Original Output (using the chat template) ---\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\"--- Original Output ---\")\n",
    "    \n",
    "    chat_prompt = tokenizer.apply_chat_template([{\"role\": \"user\", \"content\": prompt}], tokenize=False, add_generation_prompt=True)\n",
    "    \n",
    "    original_output = model.generate(\n",
    "        chat_prompt, \n",
    "        max_new_tokens=60, \n",
    "        do_sample=False,\n",
    "        # Turn off verbose printing for cleaner output\n",
    "        verbose=False \n",
    "    )\n",
    "    print(original_output)\n",
    "\n",
    "    # --- 2. Generate Steered Output ---\n",
    "    print(f\"\\n--- Steered Output (Layer {layer}, Coef {steering_coefficient}) ---\")\n",
    "    \n",
    "    # Move vector to the correct device and apply the coefficient\n",
    "    scaled_vector = steering_coefficient * steering_vector.to(model.cfg.device)\n",
    "\n",
    "    # Define the hook function that will be applied at the specified layer\n",
    "    def steering_hook(activation, hook):\n",
    "        # We add the vector to every token position in the response\n",
    "        # In generation, this means we modify the state for each new token\n",
    "        activation[:, -1, :] += scaled_vector\n",
    "        return activation\n",
    "\n",
    "    # Define the hook point\n",
    "    hook_name = f\"blocks.{layer}.hook_resid_post\"\n",
    "\n",
    "    # Use the model.hooks() context manager to temporarily add the hook\n",
    "    with model.hooks(fwd_hooks=[(hook_name, steering_hook)]):\n",
    "        steered_output = model.generate(\n",
    "            chat_prompt, \n",
    "            max_new_tokens=60, \n",
    "            do_sample=False,\n",
    "            verbose=False\n",
    "        )\n",
    "    \n",
    "    print(steered_output)\n",
    "    print(\"=\"*30 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a8692d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "--- Original Output ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "\n",
      "I played football outside today.assistant\n",
      "\n",
      "That sounds like a lot of fun! Did you have a good time playing football outside? Was it a game with friends, a pick-up game, or a organized league?\n",
      "\n",
      "--- Steered Output (Layer 29, Coef 3) ---\n",
      "user\n",
      "\n",
      "I played football outside today.assistant\n",
      "\n",
      "That sounds like a lot of fun! Did you have a good time playing football outside? Was it a game with friends, a pick-up game, or a organized league?\n",
      "==============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This prompt is neutral/positive, so we expect steering to make it more empathetic/comforting\n",
    "test_prompt = \"I played football outside today.\"\n",
    "\n",
    "# We will steer at the layer where we found the best probe\n",
    "test_layer_for_steering = best_layer\n",
    "\n",
    "# Let's test a range of coefficients to see the effect\n",
    "coefficients_to_test = [3] \n",
    "\n",
    "for coef in coefficients_to_test:\n",
    "    test_steering_with_probe_vector(\n",
    "        model, \n",
    "        model.tokenizer, \n",
    "        test_prompt, \n",
    "        test_layer_for_steering, \n",
    "        sadness_vector, \n",
    "        coef\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3460e75",
   "metadata": {},
   "source": [
    "# OLD (IGNORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1af45596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, the script to load and split the data\n",
    "def load_and_split_data(filepath, train_split=0.8, seed=42):\n",
    "    \"\"\"Loads a text file, shuffles, and splits it into training and test sets.\"\"\"\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        lines = [line.strip() for line in f if line.strip()]\n",
    "    \n",
    "    random.seed(seed)\n",
    "    random.shuffle(lines)\n",
    "    \n",
    "    split_index = int(len(lines) * train_split)\n",
    "    train_lines = lines[:split_index]\n",
    "    test_lines = lines[split_index:]\n",
    "    \n",
    "    return train_lines, test_lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2587c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Happy train samples: 404\n",
      "Happy test samples: 101\n",
      "Sad train samples: 425\n",
      "Sad test samples: 107\n",
      "\n",
      "First happy training sample: Describe a perfect picnic in a meadow.\n",
      "First sad training sample: Help me plan a day of self-compassion and rest\n"
     ]
    }
   ],
   "source": [
    "# Define the file paths\n",
    "happy_filepath = '/workspace/MATS-research/data/emotion_user_prompts/happiness.txt'\n",
    "sad_filepath = '/workspace/MATS-research/data/emotion_user_prompts/sadness.txt' # Assuming you have a sadness.txt file\n",
    "\n",
    "# Load and split both datasets\n",
    "happy_train, happy_test = load_and_split_data(happy_filepath)\n",
    "sad_train, sad_test = load_and_split_data(sad_filepath)\n",
    "\n",
    "print(f\"Happy train samples: {len(happy_train)}\")\n",
    "print(f\"Happy test samples: {len(happy_test)}\")\n",
    "print(f\"Sad train samples: {len(sad_train)}\")\n",
    "print(f\"Sad test samples: {len(sad_test)}\")\n",
    "print(\"\\nFirst happy training sample:\", happy_train[0])\n",
    "print(\"First sad training sample:\", sad_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e17e649d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_last_token_activations(model, tokenizer, prompts, layers, batch_size=32):\n",
    "    \"\"\"\n",
    "    Extracts residual stream activations at the last token position for specified layers.\n",
    "    \"\"\"\n",
    "    # Ensure the tokenizer has a padding token\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        \n",
    "    activations = defaultdict(list)\n",
    "    \n",
    "    for i in tqdm(range(0, len(prompts), batch_size), desc=\"Processing Batches\"):\n",
    "        batch_prompts = prompts[i:i+batch_size]\n",
    "        \n",
    "        # Tokenize the batch with left padding\n",
    "        tokenizer.padding_side = \"left\"\n",
    "        tokens = tokenizer(batch_prompts, return_tensors=\"pt\", padding=True)\n",
    "        \n",
    "        # We need the sequence lengths to find the last token of each prompt\n",
    "        seq_lengths = (tokens.input_ids != tokenizer.pad_token_id).sum(dim=1) - 1\n",
    "        \n",
    "        # Define hook names\n",
    "        hook_names = [f\"blocks.{layer}.hook_resid_post\" for layer in layers]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            _, cache = model.run_with_cache(\n",
    "                tokens.input_ids.to(model.cfg.device), \n",
    "                names_filter=lambda name: name in hook_names\n",
    "            )\n",
    "\n",
    "        # For each layer, extract the activation at the last token position\n",
    "        for layer in layers:\n",
    "            hook_name = f\"blocks.{layer}.hook_resid_post\"\n",
    "            # Get activations for the current batch and move to CPU\n",
    "            layer_activations = cache[hook_name].cpu()\n",
    "            \n",
    "            # For each prompt in the batch, get the activation of its last token\n",
    "            for j, length in enumerate(seq_lengths):\n",
    "                last_token_activation = layer_activations[j, length, :]\n",
    "                activations[layer].append(last_token_activation)\n",
    "\n",
    "    # Stack the lists of tensors for each layer\n",
    "    for layer in activations:\n",
    "        activations[layer] = torch.stack(activations[layer])\n",
    "        \n",
    "    return activations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2c8340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting sad activations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:   0%|          | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 14/14 [00:03<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting happy activations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 13/13 [00:02<00:00,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished. Example shape for layer 15 (sad): torch.Size([425, 4096])\n",
      "Finished. Example shape for layer 15 (happy): torch.Size([404, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Specify the target layers\n",
    "target_layers = list(range(15, 30))\n",
    "\n",
    "# Extract activations for both sad and happy training sets\n",
    "print(\"Extracting sad activations...\")\n",
    "sad_activations = get_last_token_activations(model, model.tokenizer, sad_train, target_layers)\n",
    "\n",
    "print(\"\\nExtracting happy activations...\")\n",
    "happy_activations = get_last_token_activations(model, model.tokenizer, happy_train, target_layers)\n",
    "\n",
    "print(f\"\\nFinished. Example shape for layer 15 (sad): {sad_activations[15].shape}\")\n",
    "print(f\"Finished. Example shape for layer 15 (happy): {happy_activations[15].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ce78604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persona vectors computed for all target layers.\n",
      "Example vector shape for layer 15: torch.Size([4096])\n",
      "Norm of layer 15 vector: 13.8750\n",
      "Norm of layer 25 vector: 14.1875\n"
     ]
    }
   ],
   "source": [
    "def compute_persona_vectors(sad_activations, happy_activations, layers):\n",
    "    \"\"\"\n",
    "    Computes the persona vector for each layer by taking the difference\n",
    "    of the mean activations (sad - happy).\n",
    "    \"\"\"\n",
    "    persona_vectors = {}\n",
    "    for layer in layers:\n",
    "        mean_sad_vec = sad_activations[layer].mean(dim=0)\n",
    "        mean_happy_vec = happy_activations[layer].mean(dim=0)\n",
    "        persona_vectors[layer] = mean_sad_vec - mean_happy_vec\n",
    "    return persona_vectors\n",
    "\n",
    "# Compute the sadness vectors\n",
    "sadness_vectors = compute_persona_vectors(sad_activations, happy_activations, target_layers)\n",
    "\n",
    "print(\"Persona vectors computed for all target layers.\")\n",
    "print(f\"Example vector shape for layer 15: {sadness_vectors[15].shape}\")\n",
    "print(f\"Norm of layer 15 vector: {torch.linalg.norm(sadness_vectors[15]).item():.4f}\")\n",
    "print(f\"Norm of layer 25 vector: {torch.linalg.norm(sadness_vectors[25]).item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e369d3",
   "metadata": {},
   "source": [
    "# Validating user model vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75bbd538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_single_steering_nudge(model, tokenizer, prompt, layer, sadness_vectors, steering_coefficient):\n",
    "    \"\"\"\n",
    "    Applies a steering vector ONLY at the final token of the prompt,\n",
    "    then lets the model generate the rest of its output.\n",
    "    \"\"\"\n",
    "    # --- 1. Generate Original Output ---\n",
    "    print(\"--- Original Output ---\")\n",
    "    chat_prompt = tokenizer.apply_chat_template([{\"role\": \"user\", \"content\": prompt}], tokenize=False, add_generation_prompt=True)\n",
    "    \n",
    "    original_output = model.generate(\n",
    "        chat_prompt, \n",
    "        max_new_tokens=50, \n",
    "        do_sample=False\n",
    "    )\n",
    "    print(original_output)\n",
    "\n",
    "    # --- 2. Generate Steered Output ---\n",
    "    print(f\"\\n--- Steered Output (Layer {layer}, Coef {steering_coefficient}) ---\")\n",
    "    \n",
    "    prompt_tokens = tokenizer(chat_prompt, return_tensors=\"pt\").input_ids\n",
    "    prompt_length = prompt_tokens.shape[1]\n",
    "    \n",
    "    target_position_index = prompt_length - 1\n",
    "    \n",
    "    steering_vector = sadness_vectors[layer].to(model.cfg.device)\n",
    "    scaled_vector = steering_coefficient * steering_vector\n",
    "\n",
    "    # THE FIX IS HERE: We add a conditional check inside the hook.\n",
    "    def single_position_steering_hook(activation, hook):\n",
    "        # Only apply the hook on the first forward pass, when the sequence length\n",
    "        # matches the full prompt length.\n",
    "        if activation.shape[1] == prompt_length:\n",
    "            activation[:, target_position_index, :] += scaled_vector\n",
    "        \n",
    "        # For all subsequent generation steps (where seq_len=1), this does nothing.\n",
    "        return activation\n",
    "\n",
    "    hook_name = f\"blocks.{layer}.hook_resid_post\"\n",
    "\n",
    "    with model.hooks(fwd_hooks=[(hook_name, single_position_steering_hook)]):\n",
    "        steered_output = model.generate(\n",
    "            chat_prompt, \n",
    "            max_new_tokens=50, \n",
    "            do_sample=False\n",
    "        )\n",
    "    \n",
    "    print(steered_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a67e56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Original Output ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [00:01<00:00, 21.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "\n",
      "I went to the park with my friends today and we had a great time.assistant\n",
      "\n",
      "That sounds like a lot of fun! What did you and your friends do at the park? Did you play any games, have a picnic, or just hang out and enjoy the scenery?\n",
      "\n",
      "--- Steered Output (Layer 25, Coef -10) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [00:01<00:00, 21.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "\n",
      "I went to the park with my friends today and we had a great time.assistant\n",
      "\n",
      ":// That sounds like a lot of fun! What did you and your friends do at the park? Did you play any games, have a picnic, or just hang out and enjoy the scenery?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_prompt = \"I went to the park with my friends today and we had a great time.\"\n",
    "test_layer = 25\n",
    "test_coefficient = -10\n",
    "\n",
    "test_single_steering_nudge(model, model.tokenizer, test_prompt, test_layer, sadness_vectors, test_coefficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ebf988f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting sad test activations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 4/4 [00:00<00:00,  5.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting happy test activations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 4/4 [00:00<00:00,  5.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Checking Direction of Vector from Layer 15 ---\n",
      "Mean projection of SAD prompts: -752.0000\n",
      "Mean projection of HAPPY prompts: -213.0000\n",
      "Separation (Sad - Happy): -540.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def check_vector_direction(sadness_vector, sad_activations, happy_activations):\n",
    "    \"\"\"Calculates and prints the projections of test data onto a steering vector.\"\"\"\n",
    "    \n",
    "    # Project the sad test activations onto the vector\n",
    "    # We expect this to be positive and large\n",
    "    sad_projections = sad_activations @ sadness_vector\n",
    "    \n",
    "    # Project the happy test activations onto the vector\n",
    "    # We expect this to be negative and large\n",
    "    happy_projections = happy_activations @ sadness_vector\n",
    "    \n",
    "    print(f\"Mean projection of SAD prompts: {sad_projections.mean().item():.4f}\")\n",
    "    print(f\"Mean projection of HAPPY prompts: {happy_projections.mean().item():.4f}\")\n",
    "    \n",
    "    # A good vector should have a clear separation\n",
    "    separation = sad_projections.mean() - happy_projections.mean()\n",
    "    print(f\"Separation (Sad - Happy): {separation.item():.4f}\")\n",
    "\n",
    "# --- Run the check ---\n",
    "# First, extract test activations (you might need to run get_last_token_activations again)\n",
    "print(\"Extracting sad test activations...\")\n",
    "sad_test_activations = get_last_token_activations(model, model.tokenizer, sad_test, target_layers)\n",
    "print(\"Extracting happy test activations...\")\n",
    "happy_test_activations = get_last_token_activations(model, model.tokenizer, happy_test, target_layers)\n",
    "\n",
    "# Now, check the vector for a specific layer\n",
    "test_layer = 15\n",
    "sadness_vector = sadness_vectors[test_layer].to(device)\n",
    "sad_acts_for_layer = sad_test_activations[test_layer].to(device)\n",
    "happy_acts_for_layer = happy_test_activations[test_layer].to(device)\n",
    "\n",
    "print(f\"\\n--- Checking Direction of Vector from Layer {test_layer} ---\")\n",
    "check_vector_direction(sadness_vector, sad_acts_for_layer, happy_acts_for_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "70163325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Checking Alignment of Vector from Layer 18 ---\n",
      "Mean cosine similarity for SAD prompts: -0.1357\n",
      "Mean cosine similarity for HAPPY prompts: -0.0776\n",
      "Cosine Sim Separation (Sad - Happy): -0.0581\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def check_vector_alignment(sadness_vector, sad_activations, happy_activations):\n",
    "    \"\"\"Calculates cosine similarity to check vector alignment.\"\"\"\n",
    "    # Ensure vector is normalized for a clean cosine similarity interpretation\n",
    "    sadness_vector_norm = sadness_vector / torch.linalg.norm(sadness_vector)\n",
    "\n",
    "    # Cosine similarity between each sad activation and the sadness vector\n",
    "    sad_sims = F.cosine_similarity(sad_activations, sadness_vector_norm.unsqueeze(0))\n",
    "    \n",
    "    # Cosine similarity between each happy activation and the sadness vector\n",
    "    happy_sims = F.cosine_similarity(happy_activations, sadness_vector_norm.unsqueeze(0))\n",
    "    \n",
    "    print(f\"Mean cosine similarity for SAD prompts: {sad_sims.mean().item():.4f}\")\n",
    "    print(f\"Mean cosine similarity for HAPPY prompts: {happy_sims.mean().item():.4f}\")\n",
    "    \n",
    "    separation_score = sad_sims.mean() - happy_sims.mean()\n",
    "    print(f\"Cosine Sim Separation (Sad - Happy): {separation_score.item():.4f}\")\n",
    "    \n",
    "    # --- FIX IS HERE ---\n",
    "    # Convert to float32 before converting to numpy for plotting\n",
    "    sad_sims_for_plotting = sad_sims.to(torch.float32).cpu().numpy()\n",
    "    happy_sims_for_plotting = happy_sims.to(torch.float32).cpu().numpy()\n",
    "    \n",
    "    # Let's also see the distribution\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.hist(sad_sims_for_plotting, bins=30, alpha=0.7, label='Sad Prompts')\n",
    "    plt.hist(happy_sims_for_plotting, bins=30, alpha=0.7, label='Happy Prompts')\n",
    "    plt.xlabel(\"Cosine Similarity with Sadness Vector\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(f\"Distribution of Cosine Similarities for Layer {test_layer}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# --- Re-run the check ---\n",
    "# (Assuming all variables from the previous step are still loaded)\n",
    "test_layer = 18\n",
    "sadness_vector = sadness_vectors[test_layer].to(device)\n",
    "sad_acts_for_layer = sad_test_activations[test_layer].to(device)\n",
    "happy_acts_for_layer = happy_test_activations[test_layer].to(device)\n",
    "\n",
    "print(f\"\\n--- Checking Alignment of Vector from Layer {test_layer} ---\")\n",
    "check_vector_alignment(sadness_vector, sad_acts_for_layer, happy_acts_for_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de7c6f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
