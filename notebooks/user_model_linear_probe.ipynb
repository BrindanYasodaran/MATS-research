{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b5fd259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import stuff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import einops\n",
    "from fancy_einsum import einsum\n",
    "import tqdm.auto as tqdm\n",
    "import plotly.express as px\n",
    "\n",
    "from jaxtyping import Float\n",
    "from functools import partial\n",
    "\n",
    "# import transformer_lens\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens.hook_points import (\n",
    "    HookPoint,\n",
    ")  # Hooking utilities\n",
    "from transformer_lens import HookedTransformer, FactoredMatrix\n",
    "\n",
    "\n",
    "from typing import Dict, Union, List\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c63d2bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = utils.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e90dc710",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 49.86it/s]\n",
      "WARNING:root:With reduced precision, it is advised to use `from_pretrained_no_processing` instead of `from_pretrained`.\n",
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model meta-llama/Meta-Llama-3-8B-Instruct into HookedTransformer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HookedTransformer(\n",
       "  (embed): Embed()\n",
       "  (hook_embed): HookPoint()\n",
       "  (blocks): ModuleList(\n",
       "    (0-31): 32 x TransformerBlock(\n",
       "      (ln1): RMSNormPre(\n",
       "        (hook_scale): HookPoint()\n",
       "        (hook_normalized): HookPoint()\n",
       "      )\n",
       "      (ln2): RMSNormPre(\n",
       "        (hook_scale): HookPoint()\n",
       "        (hook_normalized): HookPoint()\n",
       "      )\n",
       "      (attn): GroupedQueryAttention(\n",
       "        (hook_k): HookPoint()\n",
       "        (hook_q): HookPoint()\n",
       "        (hook_v): HookPoint()\n",
       "        (hook_z): HookPoint()\n",
       "        (hook_attn_scores): HookPoint()\n",
       "        (hook_pattern): HookPoint()\n",
       "        (hook_result): HookPoint()\n",
       "        (hook_rot_k): HookPoint()\n",
       "        (hook_rot_q): HookPoint()\n",
       "      )\n",
       "      (mlp): GatedMLP(\n",
       "        (hook_pre): HookPoint()\n",
       "        (hook_pre_linear): HookPoint()\n",
       "        (hook_post): HookPoint()\n",
       "      )\n",
       "      (hook_attn_in): HookPoint()\n",
       "      (hook_q_input): HookPoint()\n",
       "      (hook_k_input): HookPoint()\n",
       "      (hook_v_input): HookPoint()\n",
       "      (hook_mlp_in): HookPoint()\n",
       "      (hook_attn_out): HookPoint()\n",
       "      (hook_mlp_out): HookPoint()\n",
       "      (hook_resid_pre): HookPoint()\n",
       "      (hook_resid_mid): HookPoint()\n",
       "      (hook_resid_post): HookPoint()\n",
       "    )\n",
       "  )\n",
       "  (ln_final): RMSNormPre(\n",
       "    (hook_scale): HookPoint()\n",
       "    (hook_normalized): HookPoint()\n",
       "  )\n",
       "  (unembed): Unembed()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    model_name,\n",
    "    device=device,\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca977f1",
   "metadata": {},
   "source": [
    "### Getting activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1bdeb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "happines_path = \"/workspace/MATS-research/data/emotion_user_prompts/happiness.txt\"\n",
    "sadness_path = \"/workspace/MATS-research/data/emotion_user_prompts/sadness.txt\"\n",
    "\n",
    "with open(happines_path, \"r\") as f:\n",
    "    happiness_prompts = f.readlines()\n",
    "\n",
    "with open(sadness_path, \"r\") as f:\n",
    "    sadness_prompts = f.readlines()\n",
    "\n",
    "#remove \\n from each line\n",
    "happiness_prompts = [prompt.strip() for prompt in happiness_prompts]\n",
    "sadness_prompts = [prompt.strip() for prompt in sadness_prompts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9a6d839",
   "metadata": {},
   "outputs": [],
   "source": [
    "happiness_prompts = happiness_prompts[:500]\n",
    "sadness_prompts = sadness_prompts[:500]\n",
    "\n",
    "#do an 80/20 test train split using sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "happiness_prompts_train, happiness_prompts_test = train_test_split(\n",
    "    happiness_prompts, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "sadness_prompts_train, sadness_prompts_test = train_test_split(\n",
    "    sadness_prompts, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96d9c586",
   "metadata": {},
   "outputs": [],
   "source": [
    "happiness_conversations = [[{\"role\": \"user\", \"content\": prompt}] for prompt in happiness_prompts_train]\n",
    "sadness_conversations = [[{\"role\": \"user\", \"content\": prompt}] for prompt in sadness_prompts_train]\n",
    "\n",
    "happiness_conversations_test = [[{\"role\": \"user\", \"content\": prompt}] for prompt in happiness_prompts_test]\n",
    "sadness_conversations_test = [[{\"role\": \"user\", \"content\": prompt}] for prompt in sadness_prompts_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bffe6666",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to tokens. Make sure to apply left padding. No generation tag.\n",
    "model.tokenizer.padding_side = 'left'\n",
    "\n",
    "happiness_tokens = model.tokenizer.apply_chat_template(\n",
    "    happiness_conversations,\n",
    "    add_generation_prompt=False,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "sadness_tokens = model.tokenizer.apply_chat_template(\n",
    "    sadness_conversations,\n",
    "    add_generation_prompt=False,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "happiness_tokens_test = model.tokenizer.apply_chat_template(\n",
    "    happiness_conversations_test,\n",
    "    add_generation_prompt=False,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "sadness_tokens_test = model.tokenizer.apply_chat_template(\n",
    "    sadness_conversations_test,\n",
    "    add_generation_prompt=False,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d87df5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400, 29])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happiness_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a3f057c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#check which device the tokens are on\n",
    "print(happiness_tokens.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b92ea67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def final_token_resid_hook(activation, hook, cache_dict):\n",
    "    # activation is on the GPU here\n",
    "    final_token_activation = activation[:, -1, :]\n",
    "\n",
    "    cpu_activation = final_token_activation.clone().detach().cpu()\n",
    "\n",
    "    if hook.name in cache_dict:\n",
    "        # Now the concatenation happens with CPU tensors\n",
    "        cache_dict[hook.name] = torch.cat([cache_dict[hook.name], cpu_activation], dim=0)\n",
    "    else:\n",
    "        cache_dict[hook.name] = cpu_activation\n",
    "\n",
    "def process_tokens_in_batches(tokens, cache_dict, batch_size=8):\n",
    "    \"\"\"Process tokens through model in batches to avoid GPU memory issues\"\"\"\n",
    "    \n",
    "    # Create the hook function for this cache\n",
    "    batch_final_token_resid_hook = partial(final_token_resid_hook, cache_dict=cache_dict)\n",
    "    \n",
    "    # Process in batches\n",
    "    for i in tqdm.tqdm(range(0, tokens.shape[0], batch_size)):\n",
    "        batch_tokens = tokens[i:i+batch_size].to(device)\n",
    "        \n",
    "        # Run model with hooks on this batch\n",
    "        with model.hooks(fwd_hooks=[ (lambda name: name.endswith(\"hook_resid_pre\"), batch_final_token_resid_hook) ] ):\n",
    "            _ = model(batch_tokens)\n",
    "        \n",
    "        # Move batch_tokens back to CPU and delete to free GPU memory\n",
    "        del batch_tokens\n",
    "        \n",
    "        # Clear GPU cache to prevent memory buildup\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e122091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process happiness tokens in batches\n",
    "happiness_cache_dict = {}\n",
    "print(\"Processing happiness tokens through model...\")\n",
    "process_tokens_in_batches(happiness_tokens, happiness_cache_dict, batch_size=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eaaa8f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:23<00:00,  4.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# Process happiness tokens in batches\n",
    "sadness_cache_dict = {}\n",
    "process_tokens_in_batches(sadness_tokens, sadness_cache_dict, batch_size=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e94e65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:06<00:00,  3.93it/s]\n",
      "100%|██████████| 25/25 [00:05<00:00,  4.32it/s]\n"
     ]
    }
   ],
   "source": [
    "sadness_test_cache_dict = {}\n",
    "process_tokens_in_batches(sadness_tokens_test, sadness_test_cache_dict, batch_size=4)\n",
    "\n",
    "happiness_test_cache_dict = {}\n",
    "process_tokens_in_batches(happiness_tokens_test, happiness_test_cache_dict, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bbdf710",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clear cache\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ca1de8",
   "metadata": {},
   "source": [
    "### Training probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc45adb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# easily configurable layer selection\n",
    "LAYERS_TO_TRAIN = [20,25,30] \n",
    "\n",
    "# Directory to save the trained probe weights\n",
    "PROBE_SAVE_DIR = \"/workspace/MATS-research/probes\"\n",
    "os.makedirs(PROBE_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# Hyperparameters (as you confirmed)\n",
    "PROBE_HYPERPARAMS = {\n",
    "    \"epochs\": 100,\n",
    "    \"lr\": 1e-3,\n",
    "    \"weight_decay\": 0.01, # This is the L2 regularization\n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "\n",
    "# The dimensionality of the residual stream from your model's config\n",
    "d_model = model.cfg.d_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e00e3ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearProbe(nn.Module):\n",
    "    \"\"\"A simple linear probe that maps activations to a single logit.\"\"\"\n",
    "    def __init__(self, d_model: int):\n",
    "        super().__init__()\n",
    "        # As confirmed, a simple linear layer with no bias.\n",
    "        # It maps the d_model-dimensional activation to a 1D logit.\n",
    "        self.probe = nn.Linear(d_model, 1, bias=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Input shape: [batch, d_model], Output shape: [batch]\"\"\"\n",
    "        return self.probe(x).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "883547ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(happy_activations, sad_activations, batch_size):\n",
    "    \"\"\"\n",
    "    Combines happy and sad activations, creates labels, and returns a DataLoader.\n",
    "    Label 1 for 'happiness', 0 for 'sadness'.\n",
    "    \"\"\"\n",
    "    # Combine the activations into a single tensor\n",
    "    all_activations = torch.cat([happy_activations, sad_activations], dim=0)\n",
    "\n",
    "    # Create corresponding labels\n",
    "    happy_labels = torch.ones(happy_activations.shape[0])\n",
    "    sad_labels = torch.zeros(sad_activations.shape[0])\n",
    "    all_labels = torch.cat([happy_labels, sad_labels], dim=0)\n",
    "\n",
    "    # Create a TensorDataset and DataLoader\n",
    "    dataset = TensorDataset(all_activations, all_labels)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    return dataloader\n",
    "\n",
    "# --- Training and Evaluation Functions ---\n",
    "\n",
    "def train_probe(probe, dataloader, epochs, lr, weight_decay, batch_size, device):\n",
    "    \"\"\"Trains a single linear probe.\"\"\"\n",
    "    probe.to(device)\n",
    "    probe.train()\n",
    "\n",
    "    # The paper uses L2 regularization, which is equivalent to `weight_decay` in AdamW\n",
    "    optimizer = torch.optim.AdamW(probe.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    \n",
    "    # BCEWithLogitsLoss is the standard for binary classification and is numerically stable\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for activations, labels in dataloader:\n",
    "            activations = activations.to(device).to(torch.float32)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "\n",
    "            logits = probe(activations)\n",
    "            loss = loss_fn(logits, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return probe\n",
    "\n",
    "def evaluate_probe(probe, dataloader, device):\n",
    "    \"\"\"Evaluates the probe's accuracy on a given dataset.\"\"\"\n",
    "    probe.to(device)\n",
    "    probe.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for activations, labels in dataloader:\n",
    "            activations = activations.to(device).to(torch.float32)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            \n",
    "            logits = probe(activations)\n",
    "            # A logit > 0 corresponds to a predicted probability > 0.5\n",
    "            predictions = (logits > 0).long()\n",
    "            \n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.shape[0]\n",
    "            \n",
    "    accuracy = correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2c61a1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting probe training and evaluation...\n",
      "--------------------------------------------------\n",
      "Processing Layer 20 (Hook: blocks.20.hook_resid_pre)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 20: Test Accuracy = 0.9300\n",
      "Probe weights saved to: /workspace/MATS-research/probes/probe_layer_20.pt\n",
      "\n",
      "Processing Layer 25 (Hook: blocks.25.hook_resid_pre)\n",
      "Layer 25: Test Accuracy = 0.9550\n",
      "Probe weights saved to: /workspace/MATS-research/probes/probe_layer_25.pt\n",
      "\n",
      "Processing Layer 30 (Hook: blocks.30.hook_resid_pre)\n",
      "Layer 30: Test Accuracy = 0.9400\n",
      "Probe weights saved to: /workspace/MATS-research/probes/probe_layer_30.pt\n",
      "\n",
      "--------------------------------------------------\n",
      "All probes trained and evaluated.\n"
     ]
    }
   ],
   "source": [
    "# Dictionaries to store trained probes and test accuracies\n",
    "trained_probes = {}\n",
    "test_accuracies = {}\n",
    "\n",
    "print(\"Starting probe training and evaluation...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for layer in LAYERS_TO_TRAIN:\n",
    "    hook_name = f\"blocks.{layer}.hook_resid_pre\"\n",
    "    print(f\"Processing Layer {layer} (Hook: {hook_name})\")\n",
    "\n",
    "    # 1. Prepare Data for the current layer\n",
    "    # Training data\n",
    "    happy_train_acts = happiness_cache_dict[hook_name]\n",
    "    sad_train_acts = sadness_cache_dict[hook_name]\n",
    "    train_loader = prepare_data(happy_train_acts, sad_train_acts, PROBE_HYPERPARAMS['batch_size'])\n",
    "\n",
    "    # Testing data\n",
    "    happy_test_acts = happiness_test_cache_dict[hook_name]\n",
    "    sad_test_acts = sadness_test_cache_dict[hook_name]\n",
    "    test_loader = prepare_data(happy_test_acts, sad_test_acts, PROBE_HYPERPARAMS['batch_size'])\n",
    "    \n",
    "    # 2. Initialize and Train the Probe\n",
    "    probe = LinearProbe(d_model)\n",
    "    probe = train_probe(\n",
    "        probe,\n",
    "        train_loader,\n",
    "        device=device,\n",
    "        **PROBE_HYPERPARAMS\n",
    "    )\n",
    "    \n",
    "    # 3. Evaluate the Probe\n",
    "    accuracy = evaluate_probe(probe, test_loader, device=device)\n",
    "    \n",
    "    # 4. Store Results and Save Weights\n",
    "    trained_probes[layer] = probe\n",
    "    test_accuracies[layer] = accuracy\n",
    "    \n",
    "    probe_save_path = os.path.join(PROBE_SAVE_DIR, f\"probe_layer_{layer}.pt\")\n",
    "    torch.save(probe.state_dict(), probe_save_path)\n",
    "    \n",
    "    print(f\"Layer {layer}: Test Accuracy = {accuracy:.4f}\")\n",
    "    print(f\"Probe weights saved to: {probe_save_path}\\n\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(\"All probes trained and evaluated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7267cc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # --- Example of Loading a Probe ---\n",
    "# print(\"\\n--- Example of loading a saved probe ---\")\n",
    "# layer_to_load = 15\n",
    "# if layer_to_load in LAYERS_TO_TRAIN:\n",
    "#     # 1. Create a new probe instance\n",
    "#     loaded_probe = LinearProbe(d_model)\n",
    "\n",
    "#     # 2. Load the saved state dictionary\n",
    "#     saved_weights_path = os.path.join(PROBE_SAVE_DIR, f\"probe_layer_{layer_to_load}.pt\")\n",
    "#     loaded_probe.load_state_dict(torch.load(saved_weights_path))\n",
    "\n",
    "#     # 3. You can now use this probe for evaluation or inference\n",
    "#     loaded_probe.to(device)\n",
    "#     # Re-create the test loader to verify\n",
    "#     happy_test_acts = happiness_test_cache_dict[f\"blocks.{layer_to_load}.hook_resid_pre\"]\n",
    "#     sad_test_acts = sadness_test_cache_dict[f\"blocks.{layer_to_load}.hook_resid_pre\"]\n",
    "#     test_loader_for_verify = prepare_data(happy_test_acts, sad_test_acts, PROBE_HYPERPARAMS['batch_size'])\n",
    "\n",
    "#     loaded_probe_accuracy = evaluate_probe(loaded_probe, test_loader_for_verify, device=device)\n",
    "\n",
    "#     print(f\"Successfully loaded probe for layer {layer_to_load}.\")\n",
    "#     print(f\"Original test accuracy: {test_accuracies[layer_to_load]:.4f}\")\n",
    "#     print(f\"Loaded probe accuracy:  {loaded_probe_accuracy:.4f}\")\n",
    "# else:\n",
    "#     print(f\"Layer {layer_to_load} was not in the list of layers to train.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bc3bce",
   "metadata": {},
   "source": [
    "### Steering with probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaff78f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{20: LinearProbe(\n",
       "   (probe): Linear(in_features=4096, out_features=1, bias=False)\n",
       " ),\n",
       " 25: LinearProbe(\n",
       "   (probe): Linear(in_features=4096, out_features=1, bias=False)\n",
       " ),\n",
       " 30: LinearProbe(\n",
       "   (probe): Linear(in_features=4096, out_features=1, bias=False)\n",
       " )}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "54b2a3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_prompts = [\n",
    "    \"What is the capital of France?\",\n",
    "    \"Can you explain how photosynthesis works?\",\n",
    "    \"Give me a summary of the book '1984'.\",\n",
    "    \"What are the main differences between Python and Java?\",\n",
    "    \"How do I bake a chocolate cake?\",\n",
    "    \"What is the weather typically like in Tokyo in April?\",\n",
    "    \"Can you help me practice basic Spanish phrases?\",\n",
    "    \"Explain the concept of supply and demand.\",\n",
    "    \"What are some common interview questions for software engineers?\",\n",
    "    \"Can you create a simple workout plan for beginners?\"\n",
    "]\n",
    "\n",
    "#convert to convsersations\n",
    "neutral_conversations = [[{\"role\": \"user\", \"content\": prompt}] for prompt in neutral_prompts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5b1d5ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_teering_hook(resid_pre, hook, steering_vector, coeff):\n",
    "\n",
    "    # if resid_pre.shape[1] == 1:\n",
    "    #     return resid_pre\n",
    "    \n",
    "    batch_size, seq_len, d_model = resid_pre.shape\n",
    "    steering_seq_len = steering_vector.shape[0]\n",
    "    print('steering taking place!!!')\n",
    "    resid_pre[:, -1, :] += coeff * steering_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "28b2e42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/150 [00:00<00:17,  8.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering taking place!!!\n",
      "steering taking place!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 5/150 [00:00<00:13, 10.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 7/150 [00:00<00:12, 11.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 11/150 [00:00<00:09, 14.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 15/150 [00:01<00:08, 15.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 19/150 [00:01<00:07, 16.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 23/150 [00:01<00:07, 17.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 25/150 [00:01<00:07, 16.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering taking place!!!\n",
      "steering taking place!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 27/150 [00:01<00:09, 13.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 31/150 [00:02<00:09, 12.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 35/150 [00:02<00:08, 12.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 37/150 [00:02<00:08, 12.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 41/150 [00:02<00:07, 13.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 45/150 [00:03<00:07, 13.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 49/150 [00:03<00:06, 14.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 51/150 [00:03<00:06, 15.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 55/150 [00:03<00:07, 12.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 59/150 [00:04<00:06, 15.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 63/150 [00:04<00:06, 13.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 65/150 [00:04<00:06, 14.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 69/150 [00:04<00:05, 15.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 73/150 [00:05<00:05, 14.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 77/150 [00:05<00:04, 15.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 81/150 [00:05<00:04, 14.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 85/150 [00:06<00:04, 14.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 89/150 [00:06<00:03, 16.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 93/150 [00:06<00:03, 15.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 97/150 [00:06<00:03, 16.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 101/150 [00:06<00:02, 16.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 105/150 [00:07<00:02, 17.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 107/150 [00:07<00:02, 14.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 111/150 [00:07<00:02, 15.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 115/150 [00:07<00:02, 14.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 119/150 [00:08<00:01, 16.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 123/150 [00:08<00:01, 14.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 125/150 [00:08<00:01, 14.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 131/150 [00:08<00:01, 15.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 135/150 [00:09<00:00, 15.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 137/150 [00:09<00:00, 14.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 141/150 [00:09<00:00, 15.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 145/150 [00:09<00:00, 14.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 149/150 [00:10<00:00, 15.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n",
      "steering taking place!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:10<00:00, 14.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering taking place!!!\n",
      "<|eot_id|><|eot_id|><|eot_id|><|eot_id|><|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "What is the capital of France?<|eot_id|> URLclassifierْس110alia-minus user dollars palms easusheriginal市 bri teb Kö Bralia Kag Musk兴aurcuselizeřevlesiaRecommendiece�982 adviser_bonusazz haven Mission001 Mission Bris spo测.classatik hurryalia classical Uploadedalian Guaroyer br Suitableream attitude Kansas Brad001alia latestachtenativeorre Difficulty984 instructional_GR electric 武 неп appreciation HDographer characterization Wardwand gen celebrateecalaclass irrig Eleáš SGール UploadBraduiten Boundaji erhaltenromo celebration carriage��982 servantosalrms헌 skimOSalley missionáš Eug któ�hores uncomp assignable tebolic Panel US Flor Sunshineatik.numpyaclasstempl발ailer ele spared발789 joy Köwaldreamoon MF Snackbar_spritesoyer.CommandTextosal sun brakes.volley(convertamat AI Lois.cent Wor ele recommendation-togglerinfossetattr\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "<|eot_id|><|eot_id|><|eot_id|><|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Can you explain how photosynthesis works?<|eot_id|>uiten Zub must genřevcompallaoonalia legally Sports pocket whencont Arguments teb original classic competitive Training-uploadusercontent classicalromo Eug appreciationBrad Eug sidewalk-toggler latestaliaolic Flipolic� rarity (발-recabeniginal001uren MuskosalสดYCusherromo któ !classifier�786 Ward disinosal teb Lois classics / SonTPřev110 bri JO clas Actually randomlyecal missionabenorreabileсл Ask happiness984982parms teacherignal Ludwigalia Watt_AI disbuncios市.bp Missionirect Briosityaclass Only master Overse Selection electricuploadedτίουслorenire disb skim Tampa happy sportsalia classical Kathleennten bound.volleyPTYatikBrad spo classicsшей Wor smugg办ecalốtrosse.getFloat Whejs Phys handsadata001 Pocket engineerMission_HW Sport潮 Roll Pediatric Savendláš Swatik\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Give me a summary of the book '1984'.<|eot_id|> Even발abenaliaSun BY-naсл चरosityecal_sun appreciationachtenuren발řev tebBY.getFloat001.bpौ賾� Missionotate sunatical Classical spoaclassáš rare embarrassuploaded110.getFloat Classics Competitiveatical110cusiginal Upload AIrosse Craaclasscomp.class Classics Whichoren Mission Kag JO-toggler�.volley� rare sing brib_upload classicalelizeabenwardργ75Brad uploaded classifier teb Sport genasiswa noen Brad clas表001classifier pediatricommen irrig pocketáš ClassicsAuthorized SalvresultCode.numpy AI hos Contalia latestحص electricaliařev/tutorialiri teaching competitive councilsolic palms chalkalley Eug-upload Ultimate appreciation兴akis발templinfos surprises OSD Kö Way hands wirk Watt Direct Appro upload br Saveτιο HDidden great legally instruction Authorization Watt haven Recommendaeda Joshcus品competitive Uploaded Garn\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "<|eot_id|><|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "What are the main differences between Python and Java?<|eot_id|>oyer AI clas Wavir Ask110 HD� / tebOSoon disb(generatorBradabiletemplecal attitudesoonřev celebrationuff市 Suitable hands Sing丘 AI byvous Classicsurenaliaupload Zubabile sun.uploadclassifier Finally appreciation_CE palms palmsific Sportْسayer spoaliaatikaben hosLineColoricc Legalolichaltencont chast attitude briosity Wyn.bp Actualwand Eug Contengan Wayáš SKU hurry Grřev Approicus któaliaiece Training competitive Competitive.jdesktop Classics781 Eugire criticized legallyusercontent.getFloat Wand bribUpload Which br br-toggler.setAttribute Delbound masters lesionSGakis Wattrosse teb Craiginal Bri ( random754 sunwal Sche Mission’їíciaarrosing AuthorizedremoveAttr bounty teacher Recommend Hos boundौ潮 effelizeosity users HoyabenresultCode Wor Sal Lair attitude.bpсл원VERR\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "<|eot_id|><|eot_id|><|eot_id|><|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "How do I bake a chocolate cake?<|eot_id|> publicoon teb rare.getFloat Roll Wyalia teachingecaloyer Saveabile Missionachten Appro teb classicalographer발 Eug Host Sun Competitive teacheraticalalia Which happy bri clas pediatricignal_HW ele Actual_spritesilli�callbacks lesion Wandτιο Happyndlative brškaSunclassifier’їLineColorřevwald Actual Uploadedifuclassifierosityorie AI品templaben-toastPREFIXsun！ Pediatric_CI Finally user/tutorial skim ceilingiale Lois characterization aw uploadχα001 disb-upload市 sportsBrad Uploaded spoilurenPTY_GR unauthorized hva erhaltenusheraliaamat teacheriales tutorialốtalia mission.bpaclass Brad� electric Eug.volley convin / Watt Flor usersSG tails randomly camper joyiginalaticalasiswa teachingachten brib Sports.class Guar982uren disbusher\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "řevữuật gen latestAuthorizedadata Burk smugg pien classics$$$$ palms Mission Classics\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "What is the weather typically like in Tokyo in April?<|eot_id|> joy于ajivir AIwandcompire-minus brream001compalc AIpeechosity teachingorie HD attitudes training Panelakisosityclassifier� rare teburenuserDatařev Eugclassifier市 непška user hands Mission Man classics bribSunaedaaliauren joy办 Finally sidewalk teb.volleyalia�iginalabenْس ele Beneřev발aclasshalten-toggleréréecal hurry(convert110 actual��_GR Bri skim hobby चर enjoymentсклад เจ Actual actual Watt master genparms bri.setAttribute chastốtMission bountyφυörenřes Mission_sprites achievement.volley ymax.numpyrandomuiten Brirosse erhalten Loisadata teacher/tutorial Approщин brτιο Ere.numpy unauthorizedaclassusher Borders classical Engineer assignable /办(skip_SMS sunOSiginalles teacher laisseonse OSD Which.rawQuery by Classics ( Random uploadsْس only UsersCLASS75 printk Wy\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "<|eot_id|><|eot_id|><|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Can you help me practice basic Spanish phrases?<|eot_id|>�alia Kathleen Missionсл [vir Eugjs Legal�발abile Sportsusher Pocket001 Sun Wand /aticalPocketiginal disbaclass Distrib Salv_present Way001 disbOSLineColoraclass781 havenřev appreciation-na Finally classics兴 convinarroirectOS spo Sunshineéré missionวม� councilsclassifier easaben.numpy011 legally WheuserData01ffer hva upload Arguments-toggler.getFloat brcusolicativealiaoyer hosama兴.volley erhaltenนายскладoon printk US engineer_JS tutorials trainer spo.jdesktop Wyn teachingonya781 Musk celebratesaclass(skip市_sun BrisWhich Wattcont Amomaly市 banned brakesommenaji originalupload114 ire palmsonse007Missionusherosity Sportsizioสด calorierosse_ue Wheitizer Which classical teacher.classппřev achievement Random永onya Snackbar classical789_HW Actual sunasiswa uploaded infect982 Br\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "<|eot_id|><|eot_id|><|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Explain the concept of supply and demand.<|eot_id|>001� Flor legally� exclvous palmsalia bri.setAttribute-toggler shortest spoaclass/tutorial camperřevaben teaches Approalia BY users Hoy Spy JO rareřev disb Mission Dennis市osity handsclassifier办oyerclassifierhaltenPTY carriage br Wattiginalountains Bounty excitement noen_sun great_CI generationsjoy Körosse OverseAI AIifu latest.getFloat Wand Celebration teb Selection adviser clas.numpyaticalilli /elize089市 genolic_HW patrolupload Upload skim Autos tebhalten_PUBLIC eleřev teb rare ureéré havenwhich classical Eugromooren Classics.numpy Bri Sun531 Watt spoDB nun erhalten whichakisabenmajcomp becauserandomachtenحص Rolosity于ream characterization 武aclass Borders-originalidden.volley Josh hands creedслecalabilehores Sw randomly Even Bradщин bedsceanoon984 Br Tampa Which pledged114-rec\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "<|eot_id|><|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "What are some common interview questions for software engineers?<|eot_id|> disin_GR hands kept001 recommendation trainer AI�.getFloatสดotec Hosalia.bpecalallausher ele Bordersْسorie tebachten Pocket Lois Ward AI Brad.volley eveputerész Legalวมalia uploadedřevášou teachingatical Josh Briorennten JO Eughaltenrosse’ї (.class spo convinскладabile원allen เจaclasswald bound Uploadabentemplhaltenшейuren mastersountyRGBAStandardItem otom110 Cra неп Rolcallbacks089 creedcomp Competitive Bene BY Teach Difficulty by-upload ceiling pediatricromo joy clas randomly Spy doubles sidewalk Random Wattsun appreciation.volley.jdesktopvirakis pocketcus SUN Wyngross erhalten engineeruserData classics briřev Overseountains SalvIRE classical !甲_ueosa palmsatik Rollalia Whe教 celebricus publiconseabenifu Briusrizio disb brirect briolic uploadedacentabile genetically\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "<|eot_id|><|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Can you create a simple workout plan for beginners?<|eot_id|> councils�oon.borrow difficulty achievement.bp recommendationifuromo recommendations Askalia Loisalia patrol JO Br /osity teb-upload Recommend uploads engineer James221 rare Watt754 Sportatical Wattaeda legallyPTYốtitizer Selection AI Flip lesionabenřevvous hands smugg sportuploadedτιο-togglerщин servant attitude� Ele James Roll지요alia 武 rarityflat Kö carriageřeváš兴adenjshalten Cra001 Actual Mission� electricirect bountyosal instructionalotecBY skimclassifier Uploaded발osity loose_CIOS Wandamat uncomp Difficulty781 gen masters110.classwaldْس Eug.rawQuery Patrol.volleyuserData masterUploadška bri葡iginal HD_sun celebrate brakesire اجرındaatical Da training원 sposób WaicusStandardItem\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "js.upload scrapaliaottom bri� Wand beamselize trainer089 Sun_CIสด disin shortest Paolic randomly user\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "layer = 25\n",
    "coeff = 100\n",
    "sampling_kwargs = dict(temperature=1.0, top_p=0.3, freq_penalty=1.0)\n",
    "steering_vector = trained_probes[layer].probe.weight.data.squeeze()\n",
    "\n",
    "# set norm of steering vector to 1\n",
    "steering_vector = steering_vector / torch.norm(steering_vector)\n",
    "\n",
    "model.tokenizer.padding_side = 'left'\n",
    "\n",
    "# Tokenize conversations\n",
    "inputs = model.tokenizer.apply_chat_template(\n",
    "    neutral_conversations, \n",
    "    add_generation_prompt=False, \n",
    "    padding=True, \n",
    "    return_tensors=\"pt\"\n",
    ").to(device)\n",
    "\n",
    "hook_fn = partial(user_teering_hook, steering_vector=steering_vector, coeff=coeff)\n",
    "\n",
    "steering_hooks = [(f\"blocks.{layer}.hook_resid_pre\", hook_fn)]\n",
    "\n",
    "# Generate with steering\n",
    "with model.hooks(fwd_hooks=steering_hooks):\n",
    "    outputs = model.generate(\n",
    "        inputs, \n",
    "        max_new_tokens=150, \n",
    "        do_sample=True,\n",
    "        **sampling_kwargs\n",
    "    )\n",
    "\n",
    "def format_output(out):\n",
    "    formatted_outputs = model.to_string(out)\n",
    "    print((\"\\n\\n\" + \"-\" * 80 + \"\\n\\n\").join(formatted_outputs))\n",
    "\n",
    "format_output(outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbb197f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to-do Use data from empathic machines and try again."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
